<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Statistical Inference | MATH1063: Introduction to Statistics</title>
  <meta name="description" content="The course notes for MATH1063: Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Statistical Inference | MATH1063: Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="The course notes for MATH1063: Introduction to Statistics" />
  <meta name="github-repo" content="heogden/math1063" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Statistical Inference | MATH1063: Introduction to Statistics" />
  
  <meta name="twitter:description" content="The course notes for MATH1063: Introduction to Statistics" />
  

<meta name="author" content="Dr Helen Ogden, based on original notes by Prof. Sujit Sahu" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="distributions.html"/>
<link rel="next" href="lm.html"/>
<script src="libs/jquery-3.6.1/jquery-3.6.1.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#what-is-statistics"><i class="fa fa-check"></i><b>1.1</b> What is statistics?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#early-and-modern-definitions"><i class="fa fa-check"></i><b>1.1.1</b> Early and modern definitions</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#statistics-tames-uncertainty"><i class="fa fa-check"></i><b>1.1.2</b> Statistics tames uncertainty</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#why-should-i-study-statistics-as-part-of-my-degree"><i class="fa fa-check"></i><b>1.1.3</b> Why should I study statistics as part of my degree?</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#lies-damn-lies-and-statistics"><i class="fa fa-check"></i><b>1.1.4</b> Lies, Damn Lies and Statistics?</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#whats-in-this-module"><i class="fa fa-check"></i><b>1.1.5</b> What’s in this module?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#example-data-sets"><i class="fa fa-check"></i><b>1.2</b> Example data sets</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#introduction-to-r"><i class="fa fa-check"></i><b>1.3</b> Introduction to R</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#summaries"><i class="fa fa-check"></i><b>1.4</b> Summarising data sets</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#summarising-categorical-data"><i class="fa fa-check"></i><b>1.4.1</b> Summarising categorical data</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#measures-of-location"><i class="fa fa-check"></i><b>1.4.2</b> Measures of location</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#measures-of-spread"><i class="fa fa-check"></i><b>1.4.3</b> Measures of spread</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#summarising-data-in-r"><i class="fa fa-check"></i><b>1.4.4</b> Summarising data in R</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#exploratory-data-plots"><i class="fa fa-check"></i><b>1.5</b> Exploratory data plots</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i><b>1.5.1</b> Introduction</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#distribution-of-a-single-discrete-variable"><i class="fa fa-check"></i><b>1.5.2</b> Distribution of a single discrete variable</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#distribution-of-a-single-continuous-variable"><i class="fa fa-check"></i><b>1.5.3</b> Distribution of a single continuous variable</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#relationship-between-continuous-and-discrete-variables"><i class="fa fa-check"></i><b>1.5.4</b> Relationship between continuous and discrete variables</a></li>
<li class="chapter" data-level="1.5.5" data-path="index.html"><a href="index.html#relationship-between-two-continuous-variables"><i class="fa fa-check"></i><b>1.5.5</b> Relationship between two continuous variables</a></li>
<li class="chapter" data-level="1.5.6" data-path="index.html"><a href="index.html#relationships-between-more-than-two-variables"><i class="fa fa-check"></i><b>1.5.6</b> Relationships between more than two variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro-prob.html"><a href="intro-prob.html"><i class="fa fa-check"></i><b>2</b> Introduction to Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro-prob.html"><a href="intro-prob.html#definitions-of-probability"><i class="fa fa-check"></i><b>2.1</b> Definitions of probability</a></li>
<li class="chapter" data-level="2.2" data-path="intro-prob.html"><a href="intro-prob.html#some-definitions"><i class="fa fa-check"></i><b>2.2</b> Some definitions</a></li>
<li class="chapter" data-level="2.3" data-path="intro-prob.html"><a href="intro-prob.html#axioms-of-probability"><i class="fa fa-check"></i><b>2.3</b> Axioms of probability</a></li>
<li class="chapter" data-level="2.4" data-path="intro-prob.html"><a href="intro-prob.html#using-combinatorics-to-find-probabilities"><i class="fa fa-check"></i><b>2.4</b> Using combinatorics to find probabilities</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intro-prob.html"><a href="intro-prob.html#experiments-with-equally-likely-outcomes"><i class="fa fa-check"></i><b>2.4.1</b> Experiments with equally likely outcomes</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro-prob.html"><a href="intro-prob.html#sec-multiplication-rule"><i class="fa fa-check"></i><b>2.4.2</b> Multiplication rule of counting</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro-prob.html"><a href="intro-prob.html#the-number-of-permutations-of-k-from-n-pn-k"><i class="fa fa-check"></i><b>2.4.3</b> The number of permutations of <span class="math inline">\(k\)</span> from <span class="math inline">\(n\)</span>: <span class="math inline">\(P(n, k)\)</span></a></li>
<li class="chapter" data-level="2.4.4" data-path="intro-prob.html"><a href="intro-prob.html#calculation-of-probabilities-of-events-under-sampling-at-random"><i class="fa fa-check"></i><b>2.4.4</b> Calculation of probabilities of events under sampling ‘at random’</a></li>
<li class="chapter" data-level="2.4.5" data-path="intro-prob.html"><a href="intro-prob.html#a-general-urn-problem"><i class="fa fa-check"></i><b>2.4.5</b> A general ‘urn problem’</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intro-prob.html"><a href="intro-prob.html#conditional-probability-and-bayes-theorem"><i class="fa fa-check"></i><b>2.5</b> Conditional probability and Bayes’ Theorem</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intro-prob.html"><a href="intro-prob.html#definition-of-conditional-probability"><i class="fa fa-check"></i><b>2.5.1</b> Definition of conditional probability</a></li>
<li class="chapter" data-level="2.5.2" data-path="intro-prob.html"><a href="intro-prob.html#multiplication-rule-of-conditional-probability"><i class="fa fa-check"></i><b>2.5.2</b> Multiplication rule of conditional probability</a></li>
<li class="chapter" data-level="2.5.3" data-path="intro-prob.html"><a href="intro-prob.html#total-probability-formula"><i class="fa fa-check"></i><b>2.5.3</b> Total probability formula</a></li>
<li class="chapter" data-level="2.5.4" data-path="intro-prob.html"><a href="intro-prob.html#bayes-theorem"><i class="fa fa-check"></i><b>2.5.4</b> Bayes’ theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="intro-prob.html"><a href="intro-prob.html#independent-events"><i class="fa fa-check"></i><b>2.6</b> Independent events</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="intro-prob.html"><a href="intro-prob.html#introduction-and-definition-of-independence"><i class="fa fa-check"></i><b>2.6.1</b> Introduction and definition of independence</a></li>
<li class="chapter" data-level="2.6.2" data-path="intro-prob.html"><a href="intro-prob.html#independence-with-three-events"><i class="fa fa-check"></i><b>2.6.2</b> Independence with three events</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>3</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distributions.html"><a href="distributions.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="distributions.html"><a href="distributions.html#random-variables"><i class="fa fa-check"></i><b>3.2</b> Random variables</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distributions.html"><a href="distributions.html#introduction-2"><i class="fa fa-check"></i><b>3.2.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2.2" data-path="distributions.html"><a href="distributions.html#discrete-and-continuous-random-variables"><i class="fa fa-check"></i><b>3.2.2</b> Discrete and continuous random variables</a></li>
<li class="chapter" data-level="3.2.3" data-path="distributions.html"><a href="distributions.html#probability-distribution-of-a-random-variable"><i class="fa fa-check"></i><b>3.2.3</b> Probability distribution of a random variable</a></li>
<li class="chapter" data-level="3.2.4" data-path="distributions.html"><a href="distributions.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.2.4</b> Continuous random variables</a></li>
<li class="chapter" data-level="3.2.5" data-path="distributions.html"><a href="distributions.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>3.2.5</b> Cumulative distribution function (cdf)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distributions.html"><a href="distributions.html#summaries-of-a-random-variable"><i class="fa fa-check"></i><b>3.3</b> Summaries of a random variable</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="distributions.html"><a href="distributions.html#introduction-3"><i class="fa fa-check"></i><b>3.3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.3.2" data-path="distributions.html"><a href="distributions.html#expectation"><i class="fa fa-check"></i><b>3.3.2</b> Expectation</a></li>
<li class="chapter" data-level="3.3.3" data-path="distributions.html"><a href="distributions.html#variance"><i class="fa fa-check"></i><b>3.3.3</b> Variance</a></li>
<li class="chapter" data-level="3.3.4" data-path="distributions.html"><a href="distributions.html#quantiles"><i class="fa fa-check"></i><b>3.3.4</b> Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="distributions.html"><a href="distributions.html#standard-discrete-distributions"><i class="fa fa-check"></i><b>3.4</b> Standard discrete distributions</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distributions.html"><a href="distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>3.4.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="3.4.2" data-path="distributions.html"><a href="distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>3.4.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.4.3" data-path="distributions.html"><a href="distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>3.4.3</b> Geometric distribution</a></li>
<li class="chapter" data-level="3.4.4" data-path="distributions.html"><a href="distributions.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>3.4.4</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="3.4.5" data-path="distributions.html"><a href="distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>3.4.5</b> Negative binomial distribution</a></li>
<li class="chapter" data-level="3.4.6" data-path="distributions.html"><a href="distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>3.4.6</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="distributions.html"><a href="distributions.html#standard-continuous-distributions"><i class="fa fa-check"></i><b>3.5</b> Standard continuous distributions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="distributions.html"><a href="distributions.html#uniform-distribution"><i class="fa fa-check"></i><b>3.5.1</b> Uniform distribution</a></li>
<li class="chapter" data-level="3.5.2" data-path="distributions.html"><a href="distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>3.5.2</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.5.3" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>3.5.3</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="distributions.html"><a href="distributions.html#joint-distributions"><i class="fa fa-check"></i><b>3.6</b> Joint distributions</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="distributions.html"><a href="distributions.html#introduction-4"><i class="fa fa-check"></i><b>3.6.1</b> Introduction</a></li>
<li class="chapter" data-level="3.6.2" data-path="distributions.html"><a href="distributions.html#joint-distribution-of-discrete-random-variables"><i class="fa fa-check"></i><b>3.6.2</b> Joint distribution of discrete random variables</a></li>
<li class="chapter" data-level="3.6.3" data-path="distributions.html"><a href="distributions.html#joint-distribution-of-continuous-random-variables"><i class="fa fa-check"></i><b>3.6.3</b> Joint distribution of continuous random variables</a></li>
<li class="chapter" data-level="3.6.4" data-path="distributions.html"><a href="distributions.html#covariance-and-correlation"><i class="fa fa-check"></i><b>3.6.4</b> Covariance and correlation</a></li>
<li class="chapter" data-level="3.6.5" data-path="distributions.html"><a href="distributions.html#sec:indep"><i class="fa fa-check"></i><b>3.6.5</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="distributions.html"><a href="distributions.html#sec:sum-rvs"><i class="fa fa-check"></i><b>3.7</b> Sums of random variables</a></li>
<li class="chapter" data-level="3.8" data-path="distributions.html"><a href="distributions.html#sec:clt"><i class="fa fa-check"></i><b>3.8</b> The Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="distributions.html"><a href="distributions.html#introduction-5"><i class="fa fa-check"></i><b>3.8.1</b> Introduction</a></li>
<li class="chapter" data-level="3.8.2" data-path="distributions.html"><a href="distributions.html#statement-of-the-central-limit-theorem-clt"><i class="fa fa-check"></i><b>3.8.2</b> Statement of the Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="3.8.3" data-path="distributions.html"><a href="distributions.html#application-of-clt-to-binomial-distribution"><i class="fa fa-check"></i><b>3.8.3</b> Application of CLT to binomial distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>4</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inference.html"><a href="inference.html#statistical-modelling"><i class="fa fa-check"></i><b>4.1</b> Statistical modelling</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="inference.html"><a href="inference.html#introduction-6"><i class="fa fa-check"></i><b>4.1.1</b> Introduction</a></li>
<li class="chapter" data-level="4.1.2" data-path="inference.html"><a href="inference.html#statistical-models"><i class="fa fa-check"></i><b>4.1.2</b> Statistical models</a></li>
<li class="chapter" data-level="4.1.3" data-path="inference.html"><a href="inference.html#a-fully-specified-model"><i class="fa fa-check"></i><b>4.1.3</b> A fully specified model</a></li>
<li class="chapter" data-level="4.1.4" data-path="inference.html"><a href="inference.html#a-parametric-statistical-model"><i class="fa fa-check"></i><b>4.1.4</b> A parametric statistical model</a></li>
<li class="chapter" data-level="4.1.5" data-path="inference.html"><a href="inference.html#a-nonparametric-statistical-model"><i class="fa fa-check"></i><b>4.1.5</b> A nonparametric statistical model</a></li>
<li class="chapter" data-level="4.1.6" data-path="inference.html"><a href="inference.html#should-we-prefer-parametric-or-nonparametric-and-why"><i class="fa fa-check"></i><b>4.1.6</b> Should we prefer parametric or nonparametric and why?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="inference.html"><a href="inference.html#estimation"><i class="fa fa-check"></i><b>4.2</b> Estimation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="inference.html"><a href="inference.html#introduction-7"><i class="fa fa-check"></i><b>4.2.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2.2" data-path="inference.html"><a href="inference.html#population-and-sample"><i class="fa fa-check"></i><b>4.2.2</b> Population and sample</a></li>
<li class="chapter" data-level="4.2.3" data-path="inference.html"><a href="inference.html#statistic-and-estimator"><i class="fa fa-check"></i><b>4.2.3</b> Statistic and estimator</a></li>
<li class="chapter" data-level="4.2.4" data-path="inference.html"><a href="inference.html#bias-and-mean-square-error"><i class="fa fa-check"></i><b>4.2.4</b> Bias and mean square error</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inference.html"><a href="inference.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>4.3</b> Estimating the population mean</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="inference.html"><a href="inference.html#introduction-8"><i class="fa fa-check"></i><b>4.3.1</b> Introduction</a></li>
<li class="chapter" data-level="4.3.2" data-path="inference.html"><a href="inference.html#estimation-of-a-population-mean"><i class="fa fa-check"></i><b>4.3.2</b> Estimation of a population mean</a></li>
<li class="chapter" data-level="4.3.3" data-path="inference.html"><a href="inference.html#standard-deviation-and-standard-error"><i class="fa fa-check"></i><b>4.3.3</b> Standard deviation and standard error</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="inference.html"><a href="inference.html#confidence-intervals"><i class="fa fa-check"></i><b>4.4</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="inference.html"><a href="inference.html#introduction-9"><i class="fa fa-check"></i><b>4.4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.4.2" data-path="inference.html"><a href="inference.html#confidence-interval-for-a-normal-mean"><i class="fa fa-check"></i><b>4.4.2</b> Confidence interval for a normal mean</a></li>
<li class="chapter" data-level="4.4.3" data-path="inference.html"><a href="inference.html#some-remarks-about-confidence-intervals"><i class="fa fa-check"></i><b>4.4.3</b> Some remarks about confidence intervals</a></li>
<li class="chapter" data-level="4.4.4" data-path="inference.html"><a href="inference.html#confidence-intervals-using-the-clt"><i class="fa fa-check"></i><b>4.4.4</b> Confidence intervals using the CLT</a></li>
<li class="chapter" data-level="4.4.5" data-path="inference.html"><a href="inference.html#exact-confidence-interval-for-the-normal-mean"><i class="fa fa-check"></i><b>4.4.5</b> Exact confidence interval for the normal mean</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inference.html"><a href="inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="inference.html"><a href="inference.html#hypothesis-testing-in-general"><i class="fa fa-check"></i><b>4.5.1</b> Hypothesis testing in general</a></li>
<li class="chapter" data-level="4.5.2" data-path="inference.html"><a href="inference.html#testing-a-normal-mean-t-test"><i class="fa fa-check"></i><b>4.5.2</b> Testing a normal mean (t-test)</a></li>
<li class="chapter" data-level="4.5.3" data-path="inference.html"><a href="inference.html#two-sample-t-tests"><i class="fa fa-check"></i><b>4.5.3</b> Two sample t-tests</a></li>
<li class="chapter" data-level="4.5.4" data-path="inference.html"><a href="inference.html#paired-t-test"><i class="fa fa-check"></i><b>4.5.4</b> Paired t-test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>5</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="lm.html"><a href="lm.html#what-is-regression"><i class="fa fa-check"></i><b>5.1</b> What is regression?</a></li>
<li class="chapter" data-level="5.2" data-path="lm.html"><a href="lm.html#simple-linear-regression"><i class="fa fa-check"></i><b>5.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="5.3" data-path="lm.html"><a href="lm.html#estimating-the-regression-parameters"><i class="fa fa-check"></i><b>5.3</b> Estimating the regression parameters</a></li>
<li class="chapter" data-level="5.4" data-path="lm.html"><a href="lm.html#estimating-the-variance-parameter"><i class="fa fa-check"></i><b>5.4</b> Estimating the variance parameter</a></li>
<li class="chapter" data-level="5.5" data-path="lm.html"><a href="lm.html#model-fitting-in-r"><i class="fa fa-check"></i><b>5.5</b> Model fitting in R</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH1063: Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Statistical Inference<a href="inference.html#inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="statistical-modelling" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Statistical modelling<a href="inference.html#statistical-modelling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-6" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Introduction<a href="inference.html#introduction-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Statistical analysis (or inference) involves drawing conclusions, and making predictions and decisions, using the evidence provided to us by observed data. To do this we use probability distributions, often called statistical models, to describe the process by which the observed data were
generated. For example, we may suppose that the true proportion of
mature students is <span class="math inline">\(p\)</span>,
<span class="math inline">\(0 &lt; p &lt; 1\)</span>, and if we have selected <span class="math inline">\(n\)</span> students at random,
that each of those students gives rise to a
Bernoulli distribution which takes the value <span class="math inline">\(1\)</span> if the student is a
mature student and <span class="math inline">\(0\)</span>
otherwise. The
success probability of the Bernoulli distribution will be the unknown <span class="math inline">\(p\)</span>. The underlying statistical
model is then the Bernoulli distribution.</p>
<p>To illustrate with another example, suppose we have observed fast food waiting times in the
morning and afternoon, as in Example <a href="index.html#exm:fastfood">1.1</a>.
If we treat time as continuous then
the waiting time for each customer could potentially be modelled as a normal random variable.</p>
<p>In general:</p>
<ul>
<li>The form of the assumed model helps us to understand the real-world process by which the
data were generated.</li>
<li>If the model explains the observed data well, then it should also inform us about future
(or unobserved) data, and hence help us to make predictions (and decisions contingent on
unobserved data).</li>
<li>The use of statistical models, together with a carefully constructed methodology for their
analysis, also allows us to quantify the uncertainty associated with any conclusions, predictions or decisions we make.</li>
</ul>
<p>We will use the notation <span class="math inline">\(x_1 , x_2 , \ldots , x_n\)</span> to denote <span class="math inline">\(n\)</span> observations
of the random variables <span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span> (corresponding capital letters).
For the fast food waiting
time example, we have <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(x_1 = 38, x_2 = 100, \ldots, x_{20} = 70\)</span>, and
<span class="math inline">\(X_i\)</span> is the waiting time for the <span class="math inline">\(i\)</span>th person in the sample.</p>
</div>
<div id="statistical-models" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Statistical models<a href="inference.html#statistical-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we denote the complete data by the vector <span class="math inline">\(\boldsymbol{x} = (x_1 , x_2 , \ldots , x_n)\)</span> and use
<span class="math inline">\(\boldsymbol{X} = (X_1 , X_2 , \ldots , X_n)\)</span>
for the corresponding random variables. A statistical model specifies a probability distribution for
the random variables <span class="math inline">\(\boldsymbol{X}\)</span> corresponding to the data observations <span class="math inline">\(\boldsymbol{x}\)</span>. Providing a specification for
the distribution of <span class="math inline">\(n\)</span> jointly varying random variables can be a daunting task, particularly if <span class="math inline">\(n\)</span> is
large. However, this task is made much easier if we can make some simplifying assumptions, such
as</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span> are independent random variables,</li>
<li><span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span> have the same probability distribution
(so <span class="math inline">\(x_1 , x_2 , \ldots , x_n\)</span> are observations of a single random variable <span class="math inline">\(X\)</span>).</li>
</ol>
<p>Assumption 1 depends on the sampling mechanism and is very common in practice. If we are
to make this assumption for the Southampton student sampling experiment, we need to select
randomly among all possible students. The assumption will be violated when samples are correlated either in time or in space, e.g. the daily air pollution level in
Southampton for the last year or the air pollution levels in two nearby locations in Southampton.
In this module we will only consider data sets where Assumption 1 is reasonable.</p>
<p>Assumption 2 is not
always appropriate, but is often reasonable when we are modelling a single variable. In the fast
food waiting time example, we must assume that there are no differences between the AM and PM
waiting times for Assumption 2 to hold.</p>
<p>If Assumption 1 and 2 both hold, we say that <span class="math inline">\(X_1 , \ldots , X_{n}\)</span> are
independent and identically distributed (or i.i.d. for short).</p>
</div>
<div id="a-fully-specified-model" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> A fully specified model<a href="inference.html#a-fully-specified-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes a model completely specifies the probability distribution of <span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span>.
For example, if we assume that the waiting time <span class="math inline">\(X \sim N (\mu, \sigma^2)\)</span> where <span class="math inline">\(\mu = 100\)</span>, and
<span class="math inline">\(\sigma^2 = 100\)</span>, then this
is a fully specified model. In this case, there is no need to collect any data as there is no need
to make any inference about any unknown quantities, although we may use the data to judge the
plausibility of the model.
A fully specified model might be appropriate when there is some external
(to the data) theory as to why the model (in particular the values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>)
was appropriate.
Fully specified models such as this are uncommon as we rarely have external theory which allows
us to specify a model so precisely.</p>
</div>
<div id="a-parametric-statistical-model" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> A parametric statistical model<a href="inference.html#a-parametric-statistical-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A parametric statistical model specifies a probability distribution for a random sample apart from
the value of a number of parameters in that distribution. This could be confusing in the first
instance – a parametric model does not specify parameters! Here the word parametric signifies the
fact that the probability distribution is completely specified by a few parameters in the first place.
For example, the Poisson distribution is parameterised by the parameter <span class="math inline">\(\lambda\)</span> which happens
to be the
mean of the distribution; the normal distribution is parameterised by two parameters, the mean <span class="math inline">\(\mu\)</span>
and the variance <span class="math inline">\(\sigma^2\)</span>.
When a parametric statistical model is assumed with some unknown parameters, statistical
inference methods use data to estimate the unknown parameters, e.g. <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span>.
Estimation will be
discussed in more detail in the following sections.</p>
</div>
<div id="a-nonparametric-statistical-model" class="section level3 hasAnchor" number="4.1.5">
<h3><span class="header-section-number">4.1.5</span> A nonparametric statistical model<a href="inference.html#a-nonparametric-statistical-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes it is not appropriate, or we want to avoid, making a precise specification for the
distribution which generated <span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span>. For example, when the data histogram
does not show
a bell-shaped distribution, it would be wrong to assume a normal distribution for the data. In
such a case, although we can attempt to use some other non-bell-shaped parametric model, we can
decide altogether to abandon parametric models. We may then still assume that
<span class="math inline">\(X_1 , X_2 , \ldots , X_n\)</span>
are i.i.d. random variables, but from a nonparametric statistical model which cannot be written
down, having a probability function which only depends on a finite number of parameters. Such
analysis approaches are also called distribution-free methods.</p>
<div class="example">
<p><span id="exm:unlabeled-div-56" class="example"><strong>Example 4.1  (Computer failures) </strong></span>Let <span class="math inline">\(X\)</span> denote the count of computer failures per week
from Example <a href="index.html#exm:compfail">1.2</a>, summarised in the following
table:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
0
</th>
<th style="text-align:right;">
1
</th>
<th style="text-align:right;">
2
</th>
<th style="text-align:right;">
3
</th>
<th style="text-align:right;">
4
</th>
<th style="text-align:right;">
5
</th>
<th style="text-align:right;">
6
</th>
<th style="text-align:right;">
7
</th>
<th style="text-align:right;">
8
</th>
<th style="text-align:right;">
9
</th>
<th style="text-align:right;">
10
</th>
<th style="text-align:right;">
11
</th>
<th style="text-align:right;">
12
</th>
<th style="text-align:right;">
13
</th>
<th style="text-align:right;">
17
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
<p>We want to estimate how often will the
computer system fail at least once per week in the next year? The answer is <span class="math inline">\(52 \times (1 - P (X = 0))\)</span>.
But how would you estimate <span class="math inline">\(P (X = 0)\)</span>? Consider two approaches.</p>
<ol style="list-style-type: decimal">
<li><strong>Nonparametric</strong>. Estimate <span class="math inline">\(P (X = 0)\)</span> by the relative frequency of number of zeros in the
above sample, which is 12 out of 104. Thus our estimate of <span class="math inline">\(P (X = 0)\)</span> is <span class="math inline">\(12/104\)</span>. Hence,
our estimate of the number of weeks when there will be at least one computer failure is
<span class="math inline">\(52 \times (1 - 12/104) = 46\)</span>.</li>
<li><strong>Parametric</strong>. Suppose we assume that <span class="math inline">\(X\)</span> follows the Poisson distribution with parameter
<span class="math inline">\(\lambda\)</span>.
Then the answer to the above question is
<span class="math display">\[52 \times (1 - P (X = 0)) = 52 \times \left(1 - e^{-\lambda} \frac{\lambda^0}{0!} \right)
= 52 \times (1 - e^{-\lambda})\]</span>
which involves the unknown parameter <span class="math inline">\(\lambda\)</span>. For the Poisson distribution we know that <span class="math inline">\(E(X) = \lambda\)</span>. Hence we could use the sample mean <span class="math inline">\(\bar X\)</span> to estimate <span class="math inline">\(E(X) = \lambda\)</span>. Thus we estimate
<span class="math inline">\(\hat \lambda = \bar x = 3.75.\)</span> This type of estimator is called a moment estimator.
Now our estimate of the number of weeks when there will be at least one computer failure is
<span class="math inline">\(52 \times (1 - e^{-3.75}) = 50.78 \approx 51\)</span>, which is very different from our
answer of 46 from the nonparametric approach.</li>
</ol>
</div>
</div>
<div id="should-we-prefer-parametric-or-nonparametric-and-why" class="section level3 hasAnchor" number="4.1.6">
<h3><span class="header-section-number">4.1.6</span> Should we prefer parametric or nonparametric and why?<a href="inference.html#should-we-prefer-parametric-or-nonparametric-and-why" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The parametric approach should be preferred if the assumption of the Poisson distribution can
be justified for the data. For example, we can look at the data histogram or compare the fitted
probabilities of different values of <span class="math inline">\(X\)</span>, i.e. 
<span class="math display">\[\hat P (X = x) = e^{-\hat \lambda} \frac{\hat \lambda}{x!},\]</span>
with the relative frequencies from the
sample. In general, often model-based analysis is preferred because it is more precise and accurate,
and we can find estimates of uncertainty in such analysis based on the structure of the model. We
shall see this later.</p>
<p>The nonparametric approach should be preferred if the model cannot be justified for the data,
as in that case the parametric approach will provide incorrect answers.</p>
</div>
</div>
<div id="estimation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Estimation<a href="inference.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-7" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Introduction<a href="inference.html#introduction-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we have collected data and proposed a statistical model for our data, the initial statistical
analysis usually involves estimation.</p>
<ul>
<li>For a parametric model, we need to estimate the unknown (unspecified) parameter <span class="math inline">\(\lambda\)</span>. For
example, if our model for the computer failure data is that they are i.i.d. Poisson, we need to
estimate the mean (<span class="math inline">\(\lambda\)</span>) of the Poisson distribution.</li>
<li>For a nonparametric model, we may want to estimate the properties of the data-generating
distribution. For example, if our model for the computer failure data is that they are i.i.d.,
following the distribution of an unspecified common random variable <span class="math inline">\(X\)</span>, then we may want
to estimate <span class="math inline">\(\mu = E(X)\)</span> or <span class="math inline">\(\sigma^2 = \operatorname{Var}(X)\)</span>.</li>
</ul>
<p>In the following, we use the generic notation <span class="math inline">\(\theta\)</span> to denote the <em>estimand</em>
(what we want to estimate
or the parameter). For example, <span class="math inline">\(\theta\)</span> is the parameter <span class="math inline">\(\lambda\)</span> in the first example, and
<span class="math inline">\(\theta\)</span> may be either <span class="math inline">\(\mu\)</span>
or <span class="math inline">\(\sigma^2\)</span> or both in the second example.</p>
</div>
<div id="population-and-sample" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Population and sample<a href="inference.html#population-and-sample" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that a statistical model specifies a probability distribution for the random variables <span class="math inline">\(\boldsymbol{X}\)</span> corresponding to the data observations <span class="math inline">\(\boldsymbol{x}\)</span>.</p>
<ul>
<li>The observations <span class="math inline">\(\boldsymbol{x} = (x_1 , \ldots , x_n )\)</span> are called the sample, and quantities derived from the
sample are sample quantities. For example, as in Chapter 1, we call
<span class="math display">\[\bar x = \frac{1}{n} \sum_{i=1}^n x_i\]</span>
the sample mean.</li>
<li>The probability distribution for <span class="math inline">\(X\)</span> specified in our model represents all possible observations
which might have been observed in our sample, and is therefore sometimes referred to as the
population. Quantities derived from this distribution are population quantities.
For example, if our model is that <span class="math inline">\(X_1 , \ldots , X_n\)</span> are i.i.d., following
the common distribution of
a random variable <span class="math inline">\(X\)</span>, then we call <span class="math inline">\(E(X)\)</span> the <em>population mean</em>.</li>
</ul>
</div>
<div id="statistic-and-estimator" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Statistic and estimator<a href="inference.html#statistic-and-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A statistic <span class="math inline">\(T(\boldsymbol{x})\)</span> is any function of the observed data <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> alone (and therefore does not depend on any parameters or other unknowns).</p>
<p>An estimate of <span class="math inline">\(\theta\)</span> is any statistic which is used to estimate <span class="math inline">\(\theta\)</span> under a particular statistical model. We will use <span class="math inline">\(\tilde{\theta}(\boldsymbol{x})\)</span> (sometimes shortened to <span class="math inline">\(\tilde{\theta}\)</span> ) to denote an estimate of <span class="math inline">\(\theta\)</span>.</p>
<p>An estimate <span class="math inline">\(\tilde{\theta}(\boldsymbol{x})\)</span> is an observation of a corresponding random variable <span class="math inline">\(\tilde{\theta}(\boldsymbol{X})\)</span> which is called an estimator. Thus an estimate is a particular observed value, e.g. 1.2, but an estimator is a random variable which can take values which are called estimates.</p>
<p>An estimate is a particular numerical value, e.g. <span class="math inline">\(\bar{x}\)</span>; an estimator is a random variable, e.g. <span class="math inline">\(\bar{X}\)</span>.</p>
<p>The probability distribution of any estimator <span class="math inline">\(\tilde{\theta}(\boldsymbol{X})\)</span> is called its sampling distribution. The estimate <span class="math inline">\(\tilde{\theta}(\boldsymbol{x})\)</span> is an observed value (a number), and is a single observation from the sampling distribution of <span class="math inline">\(\tilde{\theta}(\boldsymbol{X})\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-57" class="example"><strong>Example 4.2  </strong></span>Suppose that we have a random sample <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> from the uniform distribution on the interval <span class="math inline">\((0, \theta)\)</span> where <span class="math inline">\(\theta&gt;0\)</span> is unknown. Suppose that <span class="math inline">\(n=5\)</span> and we have the sample observations <span class="math inline">\(x_{1}=2.3, x_{2}=3.6, x_{3}=20.2, x_{4}=0.9, x_{5}=17.2\)</span>. Our objective is to estimate <span class="math inline">\(\theta\)</span>. How can we proceed?</p>
<p>Here the pdf <span class="math inline">\(f(x)=\frac{1}{\theta}\)</span> for <span class="math inline">\(0 \leq x \leq \theta\)</span> and 0 otherwise. Hence <span class="math inline">\(E(X)=\int_{0}^{\theta} \frac{1}{\theta} x d x=\frac{\theta}{2}\)</span>. There are many possible estimators for <span class="math inline">\(\theta\)</span>, e.g. <span class="math inline">\(\hat{\theta}_{1}(\boldsymbol{X})=2 \bar{X}\)</span>, which is motivated by the method of moments because <span class="math inline">\(\theta=2 E(X)\)</span>. A second estimator is <span class="math inline">\(\hat{\theta}_{2}(\boldsymbol{X})=\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span>, which is intuitive since <span class="math inline">\(\theta\)</span> must be greater than or equal to all observed values and thus the maximum of the sample value will be closest to <span class="math inline">\(\theta\)</span>.</p>
<p>How could we choose between the two estimators <span class="math inline">\(\hat{\theta}_{1}\)</span> and <span class="math inline">\(\hat{\theta}_{2}\)</span> ? This is where we need to learn the sampling distribution of an estimator to determine which estimator will be unbiased, i.e. correct on average, and which will have minimum variability. We will formally define these in a minute, but first let us derive the sampling distribution, i.e. the pdf, of <span class="math inline">\(\hat{\theta}_{2}\)</span>. Note that <span class="math inline">\(\hat{\theta}_{2}\)</span> is a random variable since the sample <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> is random. We will first find its cdf and then differentiate the cdf to get the pdf. For ease of notation, suppose <span class="math inline">\(Y=\hat{\theta}_{2}(\boldsymbol{X})=\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span>. For any <span class="math inline">\(0&lt;y&lt;\theta\)</span>, the cdf of <span class="math inline">\(Y, F(y)\)</span> is given by
<span class="math display">\[\begin{align*}
P(Y \leq y) &amp;=P\left(\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\} \leq y\right) \\
&amp;\left.=P\left(X_{1} \leq y, X_{2} \leq y, \ldots, X_{n} \leq y\right)\right) \quad \text{since max $\leq y$ if and only if each $\leq y$}] \\
&amp;=P\left(X_{1} \leq y\right) P\left(X_{2} \leq y\right) \cdots P\left(X_{n} \leq y\right) \quad \text {since the $X_i$ are independent}\\
&amp;=\frac{y}{\theta} \times \frac{y}{\theta} \times \cdots \times \frac{y}{\theta} \\
&amp;=\left(\frac{y}{\theta}\right)^{n} .
\end{align*}\]</span></p>
<p>Now the pdf of <span class="math inline">\(Y\)</span> is
<span class="math display">\[f(y)=\frac{d F(y)}{d y}=n \frac{y^{n-1}}{\theta^{n}}, \quad 0 \leq y \leq \theta.\]</span>
Using this pdf, it can be shown that <span class="math inline">\(E\left(\hat{\theta}_{2}\right)=E(Y)=\frac{n}{n+1} \theta,\)</span> and
<span class="math display">\[\operatorname{Var}\left(\hat{\theta}_{2}\right)=\frac{n \theta^{2}}{(n+2)(n+1)^{2}}.\]</span></p>
</div>
</div>
<div id="bias-and-mean-square-error" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Bias and mean square error<a href="inference.html#bias-and-mean-square-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the uniform distribution example we saw that the estimator
<span class="math inline">\(\hat{\theta}_{2}=Y=\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span> is a random variable and its
pdf is given by <span class="math inline">\(f(y)=n \frac{y^{n-1}}{\theta^{n}}\)</span> for <span class="math inline">\(0 \leq y \leq \theta\)</span>.
This probability distribution is called the sampling distribution of <span class="math inline">\(\hat{\theta}_{2}\)</span>.
From this we have seen that <span class="math inline">\(E\left(\hat{\theta}_{2}\right)=\frac{n}{n+1} \theta\)</span>.</p>
<p>In general, we define the bias of an estimator <span class="math inline">\(\tilde{\theta}(\boldsymbol{X})\)</span> of <span class="math inline">\(\theta\)</span> to be
<span class="math display">\[\operatorname{bias}(\tilde{\theta})=E(\tilde{\theta})-\theta.\]</span></p>
<p>An estimator <span class="math inline">\(\tilde{\theta}(\boldsymbol{X})\)</span> is said to be unbiased if
<span class="math display">\[\operatorname{bias}(\tilde{\theta})=0 \text {, i.e. if } E(\tilde{\theta})=\theta.\]</span></p>
<p>So an estimator is unbiased if the expectation of its sampling distribution is equal to the quantity we are trying to estimate. Unbiased means “getting it right on average”, i.e. under repeated sampling (relative frequency interpretation of probability).</p>
<p>Thus for the uniform distribution example, <span class="math inline">\(\hat{\theta}_{2}\)</span> is a biased estimator of <span class="math inline">\(\theta\)</span> and
<span class="math display">\[\operatorname{bias}\left(\hat{\theta}_{2}\right)=E\left(\hat{\theta}_{2}\right)-\theta=\frac{n}{n+1} \theta-\theta=-\frac{1}{n+1} \theta,\]</span>
which goes to zero as <span class="math inline">\(n \rightarrow \infty\)</span>. However, <span class="math inline">\(\hat{\theta}_{1}=2 \bar{X}\)</span> is unbiased since <span class="math inline">\(E\left(\hat{\theta}_{1}\right)=2 E(\bar{X})=2 \frac{\theta}{2}=\theta\)</span>.</p>
<p>Unbiased estimators are “correct on average”, but that does not mean that they are guaranteed to provide estimates which are close to the estimand <span class="math inline">\(\theta\)</span>. A better measure of the quality of an estimator than bias is the mean squared error (or MSE), defined as
<span class="math display">\[\operatorname{MSE}(\tilde{\theta})=E\left[(\tilde{\theta}-\theta)^{2}\right]\]</span></p>
<p>Therefore, if <span class="math inline">\(\tilde{\theta}\)</span> is unbiased for <span class="math inline">\(\theta\)</span>, i.e. if <span class="math inline">\(E(\tilde{\theta})=\theta\)</span>,
then MSE <span class="math inline">\((\tilde{\theta})=\operatorname{Var}(\tilde{\theta})\)</span>. In general, we have the following result:</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-58" class="theorem"><strong>Theorem 4.1  </strong></span><span class="math display">\[\operatorname{MSE}(\tilde{\theta})=\operatorname{Var}(\tilde{\theta})+\operatorname{bias}(\tilde{\theta})^{2}\]</span></p>
</div>
<p>The proof is similar to the proof of Theorem <a href="index.html#thm:sse">1.1</a>.</p>
<div class="proof">
<p><span id="unlabeled-div-59" class="proof"><em>Proof</em>. </span><span class="math display">\[\begin{align*}
\operatorname{MSE}(\tilde{\theta}) &amp;=E\left[(\tilde{\theta}-\theta)^{2}\right] \\
&amp;=E\left[(\tilde{\theta}-E(\tilde{\theta})+E(\tilde{\theta})-\theta)^{2}\right] \\
&amp;=E\left[(\tilde{\theta}-E(\tilde{\theta}))^{2}+(E(\tilde{\theta})-\theta)^{2}+2(\tilde{\theta}-E(\tilde{\theta}))(E(\tilde{\theta})-\theta)\right] \\
&amp;=E[\tilde{\theta}-E(\tilde{\theta})]^{2}+E[E(\tilde{\theta})-\theta]^{2}+2 E[(\tilde{\theta}-E(\tilde{\theta}))(E(\tilde{\theta})-\theta)] \\
&amp;=\operatorname{Var}(\tilde{\theta})+[E(\tilde{\theta})-\theta]^{2}+2(E(\tilde{\theta})-\theta) E[(\tilde{\theta}-E(\tilde{\theta}))] \\
&amp;=\operatorname{Var}(\tilde{\theta})+\operatorname{bias}(\tilde{\theta})^{2}+2(E(\tilde{\theta})-\theta)[E(\tilde{\theta})-E(\tilde{\theta})] \\
&amp;=\operatorname{Var}(\tilde{\theta})+\operatorname{bias}(\tilde{\theta})^{2} .
\end{align*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-60" class="example"><strong>Example 4.3  </strong></span>Continuing with the uniform distribution <span class="math inline">\(U(0, \theta)\)</span> example, we have seen that <span class="math inline">\(\hat{\theta}_{1}=2 \bar{X}\)</span> is unbiased for <span class="math inline">\(\theta\)</span> but <span class="math inline">\(\operatorname{bias}\left(\hat{\theta}_{2}\right)=-\frac{1}{n+1} \theta\)</span>. How do these estimators compare with respect to the MSE? Since <span class="math inline">\(\hat{\theta}_{1}\)</span> is unbiased, its MSE is its variance. Later, we will prove that for random sampling from any population
<span class="math display">\[\operatorname{Var}(\bar{X})=\frac{\operatorname{Var}(X)}{n},\]</span>
where <span class="math inline">\(\operatorname{Var}(X)\)</span> is the variance of the population sampled from.
Returning to our example, we know that if <span class="math inline">\(X \sim U(0, \theta)\)</span> then <span class="math inline">\(\operatorname{Var}(X)=\frac{\theta^{2}}{12}\)</span>. Therefore we have
<span class="math display">\[
\operatorname{MSE}\left(\hat{\theta}_{1}\right)=\operatorname{Var}\left(\hat{\theta}_{1}\right)=\operatorname{Var}(2 \bar{X})=4 \operatorname{Var}(\bar{X})=4 \frac{\theta^{2}}{12 n}=\frac{\theta^{2}}{3 n} .
\]</span></p>
<p>Now, for <span class="math inline">\(\hat{\theta}_{2}\)</span> we know that:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\operatorname{Var}\left(\hat{\theta}_{2}\right)=\frac{n \theta^{2}}{(n+2)(n+1)^{2}}\)</span></li>
<li><span class="math inline">\(\operatorname{bias}\left(\hat{\theta}_{2}\right)=-\frac{1}{n+1} \theta\)</span>.</li>
</ol>
<p>Now
<span class="math display">\[\begin{align*}
\operatorname{MSE}\left(\hat{\theta}_{2}\right) &amp;=\operatorname{Var}\left(\hat{\theta}_{2}\right)+\operatorname{bias}\left(\hat{\theta}_{2}\right)^{2} \\
&amp;=\frac{n \theta^{2}}{(n+2)(n+1)^{2}}+\frac{\theta^{2}}{(n+1)^{2}} \\
&amp;=\frac{\theta^{2}}{(n+1)^{2}}\left(\frac{n}{n+2}+1\right) \\
&amp;=\frac{\theta^{2}}{(n+1)^{2}} \frac{2 n+2}{n+2} .
\end{align*}\]</span>
The MSE of <span class="math inline">\(\hat{\theta}_{2}\)</span> is an order of magnitude smaller than the MSE of <span class="math inline">\(\hat{\theta}_{1}\)</span>
(of order <span class="math inline">\(1/n^{2}\)</span> rather than <span class="math inline">\(1/n\)</span>), providing justification for the preference of <span class="math inline">\(\hat{\theta}_{2}=\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\)</span> as an estimator of <span class="math inline">\(\theta\)</span>.</p>
</div>
</div>
</div>
<div id="estimating-the-population-mean" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Estimating the population mean<a href="inference.html#estimating-the-population-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-8" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Introduction<a href="inference.html#introduction-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Often, one of the main tasks of a statistician is to estimate a population average or mean. However the estimates, using whatever procedure, will not be usable or scientifically meaningful if we do not know their associated uncertainties. For example, a statement such as: “the Arctic ocean will be completely ice-free in the summer in the next few decades” provides little information as it does not communicate the extent or the nature of the uncertainty in it. Perhaps a more precise statement could be: “the Arctic ocean will be completely ice-free in the summer some time in the next 20-30 years”. This last statement not only gives a numerical value for the number of years for complete ice-melt in the summer, but also acknowledges the uncertainty of <span class="math inline">\(\pm 5\)</span> years in the estimate. A statistician’s main job is to estimate such uncertainties. In this lecture, we will get started with estimating uncertainties when we estimate a population mean. We will introduce the standard error of an estimator.</p>
</div>
<div id="estimation-of-a-population-mean" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Estimation of a population mean<a href="inference.html#estimation-of-a-population-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> is a random sample from any probability distribution <span class="math inline">\(f(x)\)</span>, which may be discrete or continuous. Suppose that we want to estimate the unknown population mean <span class="math inline">\(E(X)=\mu\)</span> and variance, <span class="math inline">\(\operatorname{Var}(X)=\sigma^{2}\)</span>. In order to do this, it is not necessary to make any assumptions about <span class="math inline">\(f(x)\)</span>, so this may be thought of as nonparametric inference.</p>
<p>We have the following results:</p>
<div class="theorem">
<p><span id="thm:sample-mean-unbiased" class="theorem"><strong>Theorem 4.2  </strong></span>Suppose <span class="math inline">\(X_1, \ldots, X_n\)</span> is a random sample,
with <span class="math inline">\(E(X)=\mu\)</span>. The sample mean
<span class="math display">\[\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i}\]</span>
is an unbiased estimator of <span class="math inline">\(\mu=E(X)\)</span>, i.e. <span class="math inline">\(E(\bar{X})=\mu\)</span>.</p>
</div>
<p>In other words, the sample mean is an unbiased estimator of the population mean.</p>
<div class="proof">
<p><span id="unlabeled-div-61" class="proof"><em>Proof</em>. </span>We have
<span class="math display">\[E[\bar{X}]=\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}\right)=\frac{1}{n} \sum_{i=1}^{n} E(X)=E(X)\]</span>
so <span class="math inline">\(\bar{X}\)</span> is an unbiased estimator of <span class="math inline">\(E(X)\)</span>.</p>
</div>
<div class="theorem">
<p><span id="thm:var-sample-mean" class="theorem"><strong>Theorem 4.3  </strong></span>Suppose <span class="math inline">\(X_1, \ldots, X_n\)</span> is a random sample, with <span class="math inline">\(\operatorname{Var}(X)=\sigma^{2}\)</span>.
Then
<span class="math display">\[\operatorname{Var}(\bar{X})=\frac{\sigma^{2}}{n}.\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-62" class="proof"><em>Proof</em>. </span>We use the result that for independent random variables the variance of the sum is the sum of the variances from Section <a href="distributions.html#sec:sum-rvs">3.7</a> . Thus,
<span class="math display">\[\operatorname{Var}[\bar{X}]=\frac{1}{n^{2}} \sum_{i=1}^{n} \operatorname{Var}\left(X_{i}\right)=\frac{1}{n^{2}} \sum_{i=1}^{n} \operatorname{Var}(X)=\frac{n}{n^{2}} \operatorname{Var}(X)=\frac{\sigma^{2}}{n},\]</span></p>
</div>
<p>Together, Theorems <a href="inference.html#thm:sample-mean-unbiased">4.2</a> and <a href="inference.html#thm:var-sample-mean">4.3</a>
imply that the MSE of <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(\operatorname{Var}(X) / n\)</span>.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-63" class="theorem"><strong>Theorem 4.4  </strong></span>Suppose <span class="math inline">\(X_1, \ldots, X_n\)</span> is a random sample,
with <span class="math inline">\(\operatorname{Var}(X)=\sigma^{2}\)</span>. The sample variance with divisor <span class="math inline">\(n-1\)</span>
<span class="math display">\[S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\]</span>
is an unbiased estimator of <span class="math inline">\(\sigma^{2}\)</span>, i.e. <span class="math inline">\(E\left(S^{2}\right)=\sigma^{2}\)</span>.</p>
</div>
<p>In other words, the sample variance is an unbiased estimator of the population variance.</p>
<div class="proof">
<p><span id="unlabeled-div-64" class="proof"><em>Proof</em>. </span>We need to show
<span class="math inline">\(E\left(S^{2}\right)=\sigma^{2}\)</span>. We have
<span class="math display">\[S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\frac{1}{n-1}\left[\sum_{i=1}^{n} X_{i}^{2}-n \bar{X}^{2}\right].\]</span>
To evaluate the expectation of the above, we need <span class="math inline">\(E\left(X_{i}^{2}\right)\)</span> and <span class="math inline">\(E\left(\bar{X}^{2}\right)\)</span>. In general, we know for any random variable,
<span class="math display">\[\operatorname{Var}(Y)=E\left(Y^{2}\right)-(E(Y))^{2} \quad \Rightarrow E\left(Y^{2}\right)=\operatorname{Var}(Y)+(E(Y))^{2}.\]</span>
Thus, we have
<span class="math display">\[E\left(X_{i}^{2}\right)=\operatorname{Var}\left(X_{i}\right)+\left(E\left(X_{i}\right)\right)^{2}=\sigma^{2}+\mu^{2},\]</span>
and
<span class="math display">\[E\left(\bar{X}^{2}\right)=\operatorname{Var}(\bar{X})+(E(\bar{X}))^{2}=\sigma^{2} / n+\mu^{2},\]</span>
from Theorems <a href="inference.html#thm:sample-mean-unbiased">4.2</a> and <a href="inference.html#thm:var-sample-mean">4.3</a>.
So
<span class="math display">\[\begin{align*}
E\left(S^{2}\right) &amp;=E\left\{\frac{1}{n-1}\left[\sum_{i=1}^{n} X_{i}^{2}-n \bar{X}^{2}\right]\right\} \\
&amp;=\frac{1}{n-1}\left[\sum_{i=1}^{n} E\left(X_{i}^{2}\right)-n E\left(\bar{X}^{2}\right)\right] \\
&amp;=\frac{1}{n-1}\left[\sum_{i=1}^{n}\left(\sigma^{2}+\mu^{2}\right)-n\left(\sigma^{2} / n+\mu^{2}\right)\right] \\
&amp;=\frac{1}{n-1}\left[n \sigma^{2}+n \mu^{2}-\sigma^{2}-n \mu^{2}\right] \\
&amp;=\sigma^{2} \equiv \operatorname{Var}(X) .
\end{align*}\]</span></p>
</div>
</div>
<div id="standard-deviation-and-standard-error" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Standard deviation and standard error<a href="inference.html#standard-deviation-and-standard-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For an unbiased estimator <span class="math inline">\(\tilde{\theta}\)</span>,
<span class="math display">\[\operatorname{MSE}(\tilde{\theta})=\operatorname{Var}(\tilde{\theta})\]</span>
and therefore the sampling variance of the estimator is an important summary of its quality.</p>
<p>We usually prefer to focus on the standard deviation of the sampling distribution of <span class="math inline">\(\tilde{\theta}\)</span>,
<span class="math display">\[\text {s.d.}(\tilde{\theta})=\sqrt{\operatorname{Var}(\tilde{\theta})}.\]</span></p>
<p>In practice we will not know s.d.<span class="math inline">\((\tilde{\theta})\)</span>, as it will typically depend on unknown features of the distribution of <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>. However, we may be able to estimate s.d.<span class="math inline">\((\tilde{\theta})\)</span> using the observed sample <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span>. We define the standard error, s.e.<span class="math inline">\((\tilde{\theta})\)</span>, of an estimator <span class="math inline">\(\tilde{\theta}\)</span> to be an estimate of the standard deviation of its sampling distribution, s.d.<span class="math inline">\((\tilde{\theta})\)</span>.</p>
<p>Standard error of an estimator is an estimate of the standard deviation of its sampling distribution</p>
<p>We proved that
<span class="math display">\[\operatorname{Var}[\bar{X}]=\frac{\sigma^{2}}{n} \Rightarrow \text { s.d. }(\bar{X})=\frac{\sigma}{\sqrt{n}}.\]</span></p>
<p>As <span class="math inline">\(\sigma\)</span> is unknown, we cannot calculate this standard deviation. However, we know that <span class="math inline">\(E\left(S^{2}\right)=\sigma^{2}\)</span>, i.e. that the sample variance is an unbiased estimator of the population variance. Hence <span class="math inline">\(S^{2} / n\)</span> is an unbiased estimator for <span class="math inline">\(\operatorname{Var}(\bar{X})\)</span>. Therefore we obtain the standard error of the mean, s.e. <span class="math inline">\((\bar{X})\)</span>, by plugging in the estimate
<span class="math display">\[s=\left(\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\right)^{1 / 2}\]</span>
of <span class="math inline">\(\sigma\)</span> into s.d.<span class="math inline">\((\bar{X})\)</span> to obtain
<span class="math display">\[\text {s.e.}(\bar{X})=\frac{s}{\sqrt{n}}.\]</span></p>
<!-- TODO: refer back to computer failure data in C1 -->
<p>Therefore, for the computer failure data, our estimate, <span class="math inline">\(\bar{x}=3.75\)</span>, for the population mean is associated with a standard error
<span class="math display">\[\text{s.e.}(\bar{X})=\frac{3.381}{\sqrt{104}}=0.332.\]</span></p>
<p>Note that this is “a” standard error, so other standard errors may be available. Indeed, for parametric inference, where we make assumptions about <span class="math inline">\(f(x)\)</span>, alternative standard errors are available.
For example, if <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are i.i.d. <span class="math inline">\(\operatorname{Poisson}(\lambda)\)</span> random variables,
<span class="math inline">\(E(X)=\lambda\)</span>, so <span class="math inline">\(\bar{X}\)</span> is an unbiased estimator of <span class="math inline">\(\lambda\)</span>. <span class="math inline">\(\operatorname{Var}(X)=\lambda\)</span>, so another <span class="math inline">\(\text{s.e.}(\bar{X})=\sqrt{\hat{\lambda} / n}=\sqrt{\bar{x} / n}\)</span>.
In the computer failure data example, this is <span class="math inline">\(\sqrt{\frac{3.75}{104}}=0.19\)</span>.</p>
</div>
</div>
<div id="confidence-intervals" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Confidence intervals<a href="inference.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-9" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Introduction<a href="inference.html#introduction-9" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An estimate <span class="math inline">\(\tilde{\theta}\)</span> of a parameter <span class="math inline">\(\theta\)</span> is sometimes referred to as a point estimate. The usefulness of a point estimate is enhanced if some kind of measure of its precision can also be provided. Usually, for an unbiased estimator, this will be a standard error, an estimate of the standard deviation of the associated estimator, as we have discussed previously. An alternative summary of the information provided by the observed data about the location of a parameter <span class="math inline">\(\theta\)</span> and the associated precision is a confidence interval.</p>
<p>Suppose that <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> are observations of random variables <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> whose joint pdf is specified apart from a single parameter <span class="math inline">\(\theta\)</span>. To construct a confidence interval for <span class="math inline">\(\theta\)</span>, we need to find a random variable <span class="math inline">\(T(\mathbf{X}, \theta)\)</span> whose distribution does not depend on <span class="math inline">\(\theta\)</span> and is therefore known. This random variable <span class="math inline">\(T(\mathbf{X}, \theta)\)</span> is called a <em>pivot</em> for <span class="math inline">\(\theta\)</span>. Hence we can find numbers <span class="math inline">\(h_{1}\)</span> and <span class="math inline">\(h_{2}\)</span> such that
<span class="math display" id="eq:pivot">\[\begin{equation}
P\left(h_{1} \leq T(\mathbf{X}, \theta) \leq h_{2}\right)=1-\alpha
\tag{4.1}
\end{equation}\]</span>
where <span class="math inline">\(1-\alpha\)</span> is any specified probability. If <a href="inference.html#eq:pivot">(4.1)</a> can be ‘inverted’,we can write it as
<span class="math display">\[P\left(g_{1}(\mathbf{X}) \leq \theta \leq g_{2}(\mathbf{X})\right)=1-\alpha.\]</span></p>
<p>Hence with probability <span class="math inline">\(1-\alpha\)</span>, the parameter <span class="math inline">\(\theta\)</span> will lie between the random variables <span class="math inline">\(g_{1}(\mathbf{X})\)</span> and <span class="math inline">\(g_{2}(\mathbf{X})\)</span>. Alternatively, the random interval <span class="math inline">\(\left(g_{1}(\mathbf{X}), g_{2}(\mathbf{X})\right)\)</span> includes <span class="math inline">\(\theta\)</span> with probability <span class="math inline">\(1-\alpha\)</span>. Now, when we observe <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span>, we observe a single observation of the random interval <span class="math inline">\(\left(g_{1}(\mathbf{X}), g_{2}(\mathbf{X})\right)\)</span>, which can be evaluated as <span class="math inline">\(\left(g_{1}(\mathbf{x}), g_{2}(\mathbf{x})\right)\)</span>. We do not know if <span class="math inline">\(\theta\)</span> lies inside or outside this interval, but we do know that if we observed repeated samples, then <span class="math inline">\(100(1-\alpha) \%\)</span> of the resulting intervals would contain <span class="math inline">\(\theta\)</span>. Hence, if <span class="math inline">\(1-\alpha\)</span> is high, we can be reasonably confident that our observed interval contains <span class="math inline">\(\theta\)</span>. We call the observed interval <span class="math inline">\(\left(g_{1}(\mathbf{x}), g_{2}(\mathbf{x})\right)\)</span> a <span class="math inline">\(100(1-\alpha) \%\)</span> confidence interval for <span class="math inline">\(\theta\)</span>. It is common to present intervals with high confidence levels, usually <span class="math inline">\(90 \%, 95 \%\)</span> or <span class="math inline">\(99 \%\)</span>, so that <span class="math inline">\(\alpha=0.1,0.05\)</span> or <span class="math inline">\(0.01\)</span> respectively.</p>
</div>
<div id="confidence-interval-for-a-normal-mean" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Confidence interval for a normal mean<a href="inference.html#confidence-interval-for-a-normal-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> be i.i.d. <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> random variables.
From the Central Limit Theorem (Section <a href="distributions.html#sec:clt">3.8</a>), we know that for large <span class="math inline">\(n\)</span>,
<span class="math display">\[\bar{X} \sim N\left(\mu, \sigma^{2} / n\right) \quad \Rightarrow \quad \sqrt{n} \frac{(\bar{X}-\mu)}{\sigma} \sim N(0,1).\]</span></p>
<p>Suppose we know that <span class="math inline">\(\sigma=10\)</span>, so <span class="math inline">\(\sqrt{n}(\bar{X}-\mu) / \sigma\)</span> is a pivot for <span class="math inline">\(\mu\)</span>. Then we can use the distribution function of the standard normal distribution to find values <span class="math inline">\(h_{1}\)</span> and <span class="math inline">\(h_{2}\)</span> such that
<span class="math display">\[P\left(h_{1} \leq \sqrt{n} \frac{(\bar{X}-\mu)}{\sigma} \leq h_{2}\right)=1-\alpha\]</span>
for a chosen value of <span class="math inline">\(1-\alpha\)</span> which is called the confidence level. So <span class="math inline">\(h_{1}\)</span> and <span class="math inline">\(h_{2}\)</span> are chosen so that the shaded area in Figure <a href="inference.html#fig:normal-quantiles">4.1</a> is equal to the confidence level <span class="math inline">\(1-\alpha\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-quantiles"></span>
<img src="MATH1063_files/figure-html/normal-quantiles-1.png" alt="$h_1$ and $h_2$ are chosen to make the shaded area equal to the confidence level $1-\alpha$" width="60%" />
<p class="caption">
Figure 4.1: <span class="math inline">\(h_1\)</span> and <span class="math inline">\(h_2\)</span> are chosen to make the shaded area equal to the confidence level <span class="math inline">\(1-\alpha\)</span>
</p>
</div>
<p>It is common practice to make the interval symmetric, so that the two unshaded areas are equal
(to <span class="math inline">\(\alpha / 2\)</span> ), in which case
<span class="math display">\[-h_{1}=h_{2} \equiv h \quad \text { and } \quad \Phi(h)=1-\frac{\alpha}{2}.\]</span></p>
<p>The most common choice of confidence level is <span class="math inline">\(1-\alpha=0.95\)</span>, in which case <span class="math inline">\(h=1.96=\texttt{qnorm(0.975)}\)</span>. You may also occasionally see <span class="math inline">\(90\%\)</span> (<span class="math inline">\(h=1.645=\texttt{qnorm(0.95)}\)</span>) or
<span class="math inline">\(99\%\)</span> (<span class="math inline">\(h=2.58=\texttt{qnorm(0.995)}\)</span>) intervals.</p>
<p>Therefore we have
<span class="math display">\[\begin{align*}
&amp; P\left(-1.96 \leq \sqrt{n} \frac{(\bar{X}-\mu)}{\sigma} \leq 1.96\right)=0.95 \\
\Rightarrow &amp; P\left(\bar{X}-1.96 \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+1.96 \frac{\sigma}{\sqrt{n}}\right)=0.95 .
\end{align*}\]</span></p>
<p>Hence, <span class="math inline">\(\bar{X}-1.96 \frac{\sigma}{\sqrt{n}}\)</span> and <span class="math inline">\(\bar{X}+1.96 \frac{\sigma}{\sqrt{n}}\)</span> are the endpoints of a random interval which includes <span class="math inline">\(\mu\)</span> with probability <span class="math inline">\(0.95\)</span>. The observed value of this interval, <span class="math inline">\(\left(\bar{x} \pm 1.96 \frac{\sigma}{\sqrt{n}}\right)\)</span>, is called a 95% confidence interval for <span class="math inline">\(\mu\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-65" class="example"><strong>Example 4.4  (Fast food waiting times) </strong></span>For the fast food waiting time data, we have <span class="math inline">\(n=20\)</span> data points combined from the morning and afternoon data sets. We have <span class="math inline">\(\bar{x}=67.85\)</span> and <span class="math inline">\(n=20\)</span>. Hence, under the normal model assuming (just for the sake of illustration) <span class="math inline">\(\sigma=18\)</span>, a 95% confidence interval for <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[\begin{gathered}
67.85-1.96(18 / \sqrt{20}) \leq \mu \leq 67.85+1.96(18 / \sqrt{20}) \\
\Rightarrow 59.96 \leq \mu \leq 75.74
\end{gathered}\]</span></p>
<p>The R command is</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="inference.html#cb37-1" tabindex="-1"></a><span class="fu">mean</span>(fastfood) <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="dv">18</span> <span class="sc">/</span> <span class="fu">sqrt</span> (<span class="dv">20</span>)</span></code></pre></div>
<p>assuming <code>fastfood</code> is the vector containing 20 waiting times.</p>
<p>In reality, it is more likely that <span class="math inline">\(\sigma\)</span> is unknown in this example,
and we need to seek alternative methods for finding the confidence intervals.</p>
</div>
</div>
<div id="some-remarks-about-confidence-intervals" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Some remarks about confidence intervals<a href="inference.html#some-remarks-about-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Notice that <span class="math inline">\(\bar{x}\)</span> is an unbiased estimate of <span class="math inline">\(\mu, \sigma / \sqrt{n}\)</span> is the standard error of the estimate and <span class="math inline">\(1.96\)</span> (in general <span class="math inline">\(h\)</span> in the above discussion) is a critical value from the associated known sampling distribution. The formula <span class="math inline">\((\bar{x} \pm 1.96 \sigma / \sqrt{n})\)</span> for the confidence interval is then generalised as:
<span class="math display">\[\text { Estimate } \pm \text { Critical value } \times \text { Standard error }\]</span>
where the estimate is <span class="math inline">\(\bar{x}\)</span>, the critical value is <span class="math inline">\(1.96\)</span> and the standard error is <span class="math inline">\(\sigma / \sqrt{n}\)</span>. This is so much easier to remember. We will see that this formula holds in many of the following examples, but not all.</p></li>
<li><p>Confidence intervals are frequently used, but also frequently misinterpreted. A <span class="math inline">\(100(1-\alpha) \%\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is a single observation of a random interval which, under repeated sampling, would include <span class="math inline">\(\theta\)</span> <span class="math inline">\(100(1-\alpha) \%\)</span> of the time.</p></li>
<li><p>A confidence interval is not a probability interval. You should avoid making statements like <span class="math inline">\(P(1.3&lt;\theta&lt;2.2)=0.95\)</span>. In the classical approach to statistics you can only make probability statements about random variables, and <span class="math inline">\(\theta\)</span> is assumed to be a constant.</p></li>
<li><p>If a confidence interval is interpreted as a probability interval, this may lead to problems. For example, suppose that <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> are i.i.d. <span class="math inline">\(U\left(\theta-\frac{1}{2}, \theta+\frac{1}{2}\right)\)</span> random variables. Then <span class="math inline">\(P\left(\min \left(X_{1}, X_{2}\right)&lt;\theta&lt;\max \left(X_{1}, X_{2}\right)\right)=\frac{1}{2}\)</span> so <span class="math inline">\(\left(\min \left(x_{1}, x_{2}\right), \max \left(x_{1}, x_{2}\right)\right)\)</span> is a <span class="math inline">\(50 \%\)</span> confidence interval for <span class="math inline">\(\theta\)</span>, where <span class="math inline">\(x_{1}\)</span> and <span class="math inline">\(x_{2}\)</span> are the observed values of <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>. Now suppose that <span class="math inline">\(x_{1}=0.3\)</span> and <span class="math inline">\(x_{2}=0.9\)</span>. What is <span class="math inline">\(P(0.3&lt;\theta&lt;0.9)\)</span> ?</p></li>
</ol>
</div>
<div id="confidence-intervals-using-the-clt" class="section level3 hasAnchor" number="4.4.4">
<h3><span class="header-section-number">4.4.4</span> Confidence intervals using the CLT<a href="inference.html#confidence-intervals-using-the-clt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="introduction-10" class="section level4 hasAnchor" number="4.4.4.1">
<h4><span class="header-section-number">4.4.4.1</span> Introduction<a href="inference.html#introduction-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Confidence intervals are generally difficult to find. The difficulty lies in finding a pivot, i.e. a statistic <span class="math inline">\(T(\mathbf{X}, \theta)\)</span> such that
<span class="math display">\[P\left(h_{1} \leq T(\mathbf{X}, \theta) \leq h_{2}\right)=1-\alpha\]</span>
for two suitable numbers <span class="math inline">\(h_{1}\)</span> and <span class="math inline">\(h_{2}\)</span>, and also that the above can be inverted to put the unknown <span class="math inline">\(\theta\)</span> in the middle of the inequality inside the probability statement. One solution to this problem is to use the powerful Central Limit Theorem (CLT) to claim normality, and then basically follow the above normal example for known variance.</p>
</div>
<div id="confidence-intervals-for-mu-using-the-clt" class="section level4 hasAnchor" number="4.4.4.2">
<h4><span class="header-section-number">4.4.4.2</span> Confidence intervals for <span class="math inline">\(\mu\)</span> using the CLT<a href="inference.html#confidence-intervals-for-mu-using-the-clt" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The CLT allows us to assume the large sample approximation
<span class="math display">\[\sqrt{n} \frac{(\bar{X}-\mu)}{\sigma} \stackrel{\text { approx }}{\sim} N(0,1) \text { as } n \rightarrow \infty.\]</span>
Thus an (approximate) <span class="math inline">\(95 \%\)</span> confidence interval (CI) for <span class="math inline">\(\mu\)</span> is given by <span class="math inline">\(\bar{x} \pm 1.96 \frac{\sigma}{\sqrt{n}}\)</span>. But note that <span class="math inline">\(\sigma\)</span> is unknown so this CI cannot be used unless we can estimate <span class="math inline">\(\sigma\)</span>, i.e. replace the unknown s.d. of <span class="math inline">\(\bar{X}\)</span> by its estimated standard error. In this case, we get the CI in the familiar form:
<span class="math display">\[\text { Estimate } \pm \text { Critical value } \times \text { Standard error }\]</span></p>
<p>Suppose that we do not assume any distribution for the sampled random variable <span class="math inline">\(X\)</span> but assume only that <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are i.i.d, following the distribution of <span class="math inline">\(X\)</span> where <span class="math inline">\(E(X)=\mu\)</span> and <span class="math inline">\(\operatorname{Var}(X)=\sigma^{2}\)</span>. We know that the standard error of <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(s / \sqrt{n}\)</span> where <span class="math inline">\(s\)</span> is the sample standard deviation with divisor <span class="math inline">\(n-1\)</span>. Then the following provides an (approximate) <span class="math inline">\(95 \%\)</span> CI for <span class="math inline">\(\mu\)</span>:
<span class="math display">\[\bar{x} \pm 1.96 \frac{s}{\sqrt{n}}.\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-66" class="example"><strong>Example 4.5  (Computer failures) </strong></span>For the computer failure data, <span class="math inline">\(\bar{x}=3.75, s=3.381\)</span> and <span class="math inline">\(n=104\)</span>. Under the model that the data are observations of i.i.d. random variables with population mean <span class="math inline">\(\mu\)</span> (but no other assumptions about the underlying distribution), we compute a 95% confidence interval for <span class="math inline">\(\mu\)</span> to be
<span class="math display">\[\left(3.75-1.96 \frac{3.381}{\sqrt{104}}, 3.75+1.96 \frac{3.381}{\sqrt{104}}\right)=(3.10,4.40).\]</span></p>
</div>
<p>If we can assume a distribution for <span class="math inline">\(X\)</span>, i.e. a parametric model for <span class="math inline">\(X\)</span>, then we can do slightly better in estimating the standard error of <span class="math inline">\(\bar{X}\)</span> and as a result we can improve upon the previously obtained <span class="math inline">\(95 \%\)</span> CI. Two examples follow.</p>
<div class="example">
<p><span id="exm:poisson-ci-simple" class="example"><strong>Example 4.6  (Poisson) </strong></span>If <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are modelled as i.i.d. Poisson <span class="math inline">\((\lambda)\)</span> random variables, then <span class="math inline">\(\mu=\lambda\)</span> and <span class="math inline">\(\sigma^{2}=\lambda\)</span>. We know <span class="math inline">\(\operatorname{Var}(\bar{X})=\sigma^{2} / n=\lambda / n\)</span>. Hence a standard error is <span class="math inline">\(\sqrt{\hat{\lambda} / n}=\sqrt{\bar{x} / n}\)</span> since <span class="math inline">\(\hat{\lambda}=\bar{X}\)</span> is an unbiased estimator of <span class="math inline">\(\lambda\)</span>. Thus a 95% CI for <span class="math inline">\(\mu=\lambda\)</span> is given by
<span class="math display">\[\bar{x} \pm 1.96 \sqrt{\frac{\bar{x}}{n}}.\]</span></p>
<p>For the computer failure data, <span class="math inline">\(\bar{x}=3.75, s=3.381\)</span> and <span class="math inline">\(n=104\)</span>. Under the model that the data are observations of i.i.d. random variables following a Poisson distribution with population mean <span class="math inline">\(\lambda\)</span>, we compute a <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\lambda\)</span> as
<span class="math display">\[\bar{x} \pm 1.96 \sqrt{\frac{\bar{x}}{n}}=3.75 \pm 1.96 \sqrt{3.75 / 104}=(3.38,4.12).\]</span></p>
<p>We see that this interval is narrower <span class="math inline">\((0.74=4.12-3.38)\)</span> than the earlier interval <span class="math inline">\((3.10,4.40)\)</span>, which has a length of <span class="math inline">\(1.3\)</span>. We prefer narrower confidence intervals as they facilitate more accurate inference regarding the unknown parameter.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-67" class="example"><strong>Example 4.7  (Bernoulli) </strong></span>If <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are modelled as i.i.d. Bernoulli <span class="math inline">\((p)\)</span> random variables, then <span class="math inline">\(\mu=p\)</span> and <span class="math inline">\(\sigma^{2}=p(1-p)\)</span>. We know <span class="math inline">\(\operatorname{Var}(\bar{X})=\sigma^{2} / n=p(1-p) / n\)</span>. Hence a standard error is <span class="math inline">\(\sqrt{\hat{p}(1-\hat{p}) / n}=\sqrt{\bar{x}(1-\bar{x}) / n}\)</span>, since <span class="math inline">\(\hat{p}=\bar{X}\)</span> is an unbiased estimator of <span class="math inline">\(p\)</span>. Thus a <span class="math inline">\(95 \%\)</span> CI for <span class="math inline">\(\mu=p\)</span> is given by
<span class="math display">\[\bar{x} \pm 1.96 \sqrt{\frac{\bar{x}(1-\bar{x})}{n}}.\]</span></p>
<p>For the example, suppose <span class="math inline">\(\bar{x}=0.2\)</span> and <span class="math inline">\(n=10\)</span>. Then we obtain the <span class="math inline">\(95 \%\)</span> CI as
<span class="math display">\[0.2 \pm 1.96 \sqrt{(0.2 \times 0.8) / 10}=(-0.048,0.448)\]</span></p>
<p>Here <span class="math inline">\(n\)</span> is too small for the large sample approximation to be accurate.</p>
</div>
</div>
</div>
<div id="exact-confidence-interval-for-the-normal-mean" class="section level3 hasAnchor" number="4.4.5">
<h3><span class="header-section-number">4.4.5</span> Exact confidence interval for the normal mean<a href="inference.html#exact-confidence-interval-for-the-normal-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For normal models we do not have to rely on large sample approximations, because it turns out that the distribution of
<span class="math display">\[T=\frac{\sqrt{n}(\bar{X}-\mu)}{S},\]</span>
where <span class="math inline">\(S^{2}\)</span> is the sample variance with divisor <span class="math inline">\(n-1\)</span>, is standard (easily calculated) and thus the statistic <span class="math inline">\(T=T(\mathbf{X}, \mu)\)</span> can be an exact pivot for any sample size <span class="math inline">\(n&gt;1\)</span>.</p>
<p>The point about easy calculation is that for any given <span class="math inline">\(1-\alpha\)</span>, e.g. <span class="math inline">\(1-\alpha=0.95\)</span>, we can calculate the critical value <span class="math inline">\(h\)</span> such that <span class="math inline">\(P(-h&lt;T&lt;h)=1-\alpha\)</span>. Note also that the pivot <span class="math inline">\(T\)</span> does not involve the other unknown parameter of the normal model, namely the variance <span class="math inline">\(\sigma^{2}\)</span>. If indeed, we can find <span class="math inline">\(h\)</span> for any given <span class="math inline">\(1-\alpha\)</span>, then proceed as follows to find the exact CI for <span class="math inline">\(\mu\)</span> :
<span class="math display">\[\begin{align*}
&amp; P(-h \leq T \leq h)=1-\alpha \\
\text { i.e. } &amp; P\left(-h \leq \sqrt{n} \frac{(\bar{X}-\mu)}{S} \leq h\right)=0.95 \\
\Rightarrow &amp; P\left(\bar{X}-h \frac{S}{\sqrt{n}} \leq \mu \leq \bar{X}+h \frac{S}{\sqrt{n}}\right)=0.95
\end{align*}\]</span></p>
<p>The observed value of this interval, <span class="math inline">\(\left(\bar{x} \pm h \frac{s}{\sqrt{n}}\right)\)</span>, is the <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\mu\)</span>. Remarkably, this also of the general form,
<span class="math display">\[\text { Estimate } \pm \text { Critical value } \times \text { Standard error },\]</span>
where the critical value is <span class="math inline">\(h\)</span> and the standard error of the sample mean is <span class="math inline">\(\frac{s}{\sqrt{n}}\)</span>.
Now, how do we find the critical value <span class="math inline">\(h\)</span> for a given <span class="math inline">\(1-\alpha\)</span> ? We need to introduce the <span class="math inline">\(t\)</span>-distribution.</p>
<p>Let <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> be i.i.d <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> random variables. Define <span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i}\)</span> and
<span class="math display">\[S^{2}=\frac{1}{n-1}\left(\sum_{i=1}^{n} X_{i}^{2}-n \bar{X}^{2}\right).\]</span>
Then, it can be shown (and will be in MATH2011) that
<span class="math display">\[\sqrt{n} \frac{(\bar{X}-\mu)}{S} \sim t_{n-1},\]</span>
where <span class="math inline">\(t_{n-1}\)</span> denotes the standard <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. The standard <span class="math inline">\(t\)</span> distribution is a family of distributions which depend on one parameter called the degrees-of-freedom (df) which is <span class="math inline">\(n-1\)</span> here. The concept of degrees of freedom is that it is usually the number of independent random samples, <span class="math inline">\(n\)</span> here, minus the number of linear parameters estimated, 1 here for <span class="math inline">\(\mu\)</span>. Hence the df is <span class="math inline">\(n-1\)</span>.</p>
<p>The probability density function of the <span class="math inline">\(t_{k}\)</span> distribution is similar to a standard normal, in that it is symmetric around zero and ‘bell-shaped’, but the t-distribution is more heavy-tailed, giving greater probability to observations further away from zero. Figure <a href="inference.html#fig:t-pdf">4.2</a> illustrates the <span class="math inline">\(t_{k}\)</span> density function for various values of <span class="math inline">\(k\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:t-pdf"></span>
<img src="MATH1063_files/figure-html/t-pdf-1.png" alt="The pdf of the $t_k$ distribution for various values of $k$. The dashed line is the standard normal pdf." width="60%" />
<p class="caption">
Figure 4.2: The pdf of the <span class="math inline">\(t_k\)</span> distribution for various values of <span class="math inline">\(k\)</span>. The dashed line is the standard normal pdf.
</p>
</div>
<p>The values of <span class="math inline">\(h\)</span> for a given <span class="math inline">\(1-\alpha\)</span> can be obtained using the R command (abbreviation for quantile of <span class="math inline">\(t\)</span> ). For example, we can find <span class="math inline">\(h\)</span> for <span class="math inline">\(1-\alpha=0.95\)</span> and <span class="math inline">\(n=20\)</span></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="inference.html#cb38-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">19</span>)</span></code></pre></div>
<pre><code>## [1] 2.093024</code></pre>
<p>Note that it should be <span class="math inline">\(0.975\)</span> so that we are splitting <span class="math inline">\(0.05\)</span> probability between the two tails equally and the df should be <span class="math inline">\(n-1=19\)</span>. Indeed, modifying the above command, we obtain the following critical values for the <span class="math inline">\(95 \%\)</span> interval for different values of the sample size <span class="math inline">\(n\)</span>.</p>
<p>Note that the critical value approaches <span class="math inline">\(1.96\)</span> (which is the critical value for the normal distribution) as <span class="math inline">\(n \rightarrow \infty\)</span>, since the <span class="math inline">\(t\)</span>-distribution itself approaches the normal distribution for large values of its df parameter.</p>
<p>If you can justify that the underlying distribution is normal then you
can use the <span class="math inline">\(t\)</span>-distribution-based confidence interval.</p>
<div class="example">
<p><span id="exm:unlabeled-div-68" class="example"><strong>Example 4.8  (Fast food waiting times) </strong></span>We would like to find a confidence interval for the true mean waiting time. If <span class="math inline">\(X\)</span> denotes the waiting time in seconds, we have <span class="math inline">\(n=20, \bar{x}=67.85\)</span>, <span class="math inline">\(s=18.36\)</span>. Hence, recalling that the critical value <span class="math inline">\(h=2.093\)</span>, from the command , a <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is
<span class="math display">\[\begin{align*}
67.85-2.093 \times 18.36 / \sqrt{20} \leq \mu &amp; \leq 67.85+2.093 \times 18.36 / \sqrt{20} \\
\Rightarrow 59.26 &amp; \leq \mu \leq 76.44 .
\end{align*}\]</span></p>
<p>In R, if the vector <code>fastfood</code> contains all the service times,
we can find a <span class="math inline">\(95 \%\)</span> confidence interval with</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="inference.html#cb40-1" tabindex="-1"></a><span class="fu">mean</span>(fastfood) <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">19</span>) <span class="sc">*</span> <span class="fu">sd</span>(fastfood) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span></code></pre></div>
<pre><code>## [1] 59.25467 76.44533</code></pre>
<p>or a <span class="math inline">\(90 \%\)</span> confidence interval with</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="inference.html#cb42-1" tabindex="-1"></a><span class="fu">mean</span>(fastfood) <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qt</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">19</span>) <span class="sc">*</span> <span class="fu">sd</span>(fastfood) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span></code></pre></div>
<pre><code>## [1] 60.74905 74.95095</code></pre>
<p>or a <span class="math inline">\(99 \%\)</span> confidence interval with</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="inference.html#cb44-1" tabindex="-1"></a><span class="fu">mean</span>(fastfood) <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">qt</span>(<span class="fl">0.995</span>, <span class="at">df =</span> <span class="dv">19</span>) <span class="sc">*</span> <span class="fu">sd</span>(fastfood) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span></code></pre></div>
<pre><code>## [1] 56.10113 79.59887</code></pre>
<p>We can see clearly that the interval gets wider as the level of confidence is gets higher.</p>
</div>
<div class="example">
<p><span id="exm:wtgain-ci" class="example"><strong>Example 4.9  (Weight gain) </strong></span>Returning to the weight gain data from Example <a href="index.html#exm:wtgain">1.3</a>,
we would like to find a confidence interval for the true average weight gain (final weight - initial weight). Here <span class="math inline">\(n=68, \bar{x}=0.8672\)</span> and <span class="math inline">\(s=0.9653\)</span>. Hence, a <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is
<span class="math display">\[\begin{align*}
0.8672-1.996 \times 0.9653 / \sqrt{68} \leq \mu &amp; \leq 0.8672+1.996 \times 0.9653 / \sqrt{68} \\
\Rightarrow 0.6335 &amp; \leq \mu \leq 1.1008
\end{align*}\]</span></p>
<p>In R, we obtain the critical value <span class="math inline">\(1.996\)</span> by</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="inference.html#cb46-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">67</span>)</span></code></pre></div>
<pre><code>## [1] 1.996008</code></pre>
<p>Note that the interval here does not include the value 0, so it is very likely that the weight gain is significantly positive, which we will justify using what is called hypothesis testing.</p>
</div>
</div>
</div>
<div id="hypothesis-testing" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Hypothesis testing<a href="inference.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="hypothesis-testing-in-general" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Hypothesis testing in general<a href="inference.html#hypothesis-testing-in-general" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="introduction-11" class="section level4 hasAnchor" number="4.5.1.1">
<h4><span class="header-section-number">4.5.1.1</span> Introduction<a href="inference.html#introduction-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The manager of a new fast food chain claims that the average waiting time to be served in their restaurant is less than a minute. The marketing department of a mobile phone company claims that their phones never break down in the first three years of their lifetime. A professor of nutrition claims that students gain significant weight in the first year of their life in college away form home. How can we verify these claims? We will learn the procedures of hypothesis testing for such problems.</p>
<p>In statistical inference, we use observations <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> of univariate random variables <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> in order to draw inferences about the probability distribution <span class="math inline">\(f(x)\)</span> of the underlying random variable <span class="math inline">\(X\)</span>. So far, we have mainly been concerned with estimating features (usually unknown parameters) of <span class="math inline">\(f(x)\)</span>. It is often of interest to compare alternative specifications for <span class="math inline">\(f(x)\)</span>. If we have a set of competing probability models which might have generated the observed data, we may want to determine which of the models is most appropriate. A proposed (hypothesised) model for <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> is then referred to as a hypothesis, and pairs of models are compared using hypothesis tests.</p>
<p>For example, we may have two competing alternatives, <span class="math inline">\(f^{(0)}(x)\)</span> (model <span class="math inline">\(H_{0}\)</span>) and <span class="math inline">\(f^{(1)}(x)\)</span> (model <span class="math inline">\(H_{1}\)</span>) for <span class="math inline">\(f(x)\)</span>, both of which completely specify the joint distribution of the sample <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>. Completely specified statistical models are called simple hypotheses. Usually, <span class="math inline">\(H_{0}\)</span> and <span class="math inline">\(H_{1}\)</span> both take the same parametric form <span class="math inline">\(f(x, \theta)\)</span>, but with different values <span class="math inline">\(\theta^{(0)}\)</span> and <span class="math inline">\(\theta^{(1)}\)</span> of <span class="math inline">\(\theta\)</span>. Thus the joint distribution of the sample given by <span class="math inline">\(f(\mathbf{X})\)</span> is completely specified apart from the values of the unknown parameter <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\theta^{(0)} \neq \theta^{(1)}\)</span> are specified alternative values.</p>
<p>More generally, competing hypotheses often do not completely specify the joint distribution of <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>. For example, a hypothesis may state that <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> is a random sample from the probability distribution <span class="math inline">\(f(x ; \theta)\)</span> where <span class="math inline">\(\theta&lt;0\)</span>. This is not a completely specified hypothesis, since it is not possible to calculate probabilities such as <span class="math inline">\(P\left(X_{1}&lt;2\right)\)</span> when the hypothesis is true, as we do not know the exact value of <span class="math inline">\(\theta\)</span>. Such an hypothesis is called a composite hypothesis.</p>
<p>Examples of hypotheses:</p>
<ul>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim N\left(\mu, \sigma^{2}\right)\)</span> with <span class="math inline">\(\mu=0, \sigma^{2}=2\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim N\left(\mu, \sigma^{2}\right)\)</span> with <span class="math inline">\(\mu=0, \sigma^{2} \in \mathcal{R}_{+}\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim N\left(\mu, \sigma^{2}\right)\)</span> with <span class="math inline">\(\mu \neq 0, \sigma^{2} \in \mathcal{R}_{+}\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim \operatorname{Bernoulli}(p)\)</span> with <span class="math inline">\(p=\frac{1}{2}\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim \operatorname{Bernoulli}(p)\)</span> with <span class="math inline">\(p \neq \frac{1}{2}\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim \operatorname{Bernoulli}(p)\)</span> with <span class="math inline">\(p&gt;\frac{1}{2}\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim \operatorname{Poisson}(\lambda)\)</span> with <span class="math inline">\(\lambda=1\)</span>.</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n} \sim \operatorname{Poisson}(\theta)\)</span> with <span class="math inline">\(\theta&gt;1\)</span></li>
</ul>
</div>
<div id="hypothesis-testing-procedure" class="section level4 hasAnchor" number="4.5.1.2">
<h4><span class="header-section-number">4.5.1.2</span> Hypothesis testing procedure<a href="inference.html#hypothesis-testing-procedure" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A hypothesis test provides a mechanism for comparing two competing statistical models, <span class="math inline">\(H_{0}\)</span> and <span class="math inline">\(H_{1}\)</span>. A hypothesis test does not treat the two hypotheses (models) symmetrically. One hypothesis, <span class="math inline">\(H_{0}\)</span>, is given special status, and referred to as the null hypothesis. The null hypothesis is the reference model, and is assumed to be appropriate unless the observed data strongly indicate that <span class="math inline">\(H_{0}\)</span> is inappropriate, and that <span class="math inline">\(H_{1}\)</span> (the alternative hypothesis) should be preferred. Hence, the fact that a hypothesis test does not reject <span class="math inline">\(H_{0}\)</span> should not be taken as evidence that <span class="math inline">\(H_{0}\)</span> is true and <span class="math inline">\(H_{1}\)</span> is not, or that <span class="math inline">\(H_{0}\)</span> is better-supported by the data than <span class="math inline">\(H_{1}\)</span>, merely that the data does not provide significant evidence to reject <span class="math inline">\(H_{0}\)</span> in favour of <span class="math inline">\(H_{1}\)</span>.</p>
<p>A hypothesis test is defined by its critical region or rejection region, which we shall denote by <span class="math inline">\(C\)</span>. <span class="math inline">\(C\)</span> is a subset of <span class="math inline">\(\mathcal{R}^{n}\)</span> and is the set of possible observed values of <span class="math inline">\(\mathbf{X}\)</span> which, if observed, would lead to rejection of <span class="math inline">\(H_{0}\)</span> in favour of <span class="math inline">\(H_{1}\)</span>, i.e.</p>
<p><span class="math display">\[
\begin{array}{ll}
\text { If } \mathbf{x} \in C &amp; H_{0} \text { is rejected in favour of } H_{1} \\
\text { If } \mathbf{x} \notin C &amp; H_{0} \text { is not rejected }
\end{array}
\]</span></p>
<p>As <span class="math inline">\(\mathbf{X}\)</span> is a random variable, there remains the possibility that a hypothesis test will give an erroneous result. We define two types of error:</p>
<p>The following table helps to understand further:</p>
<p>When <span class="math inline">\(H_{0}\)</span> and <span class="math inline">\(H_{1}\)</span> are simple hypotheses, we can define
<span class="math display">\[\begin{align*}
&amp; \alpha=P(\text {Type I error})=P(\mathbf{X} \in C) \quad \text { if $H_{0}$ is true } \\
&amp; \beta=P(\text {Type II error})=P(\mathbf{X} \notin C) \quad \text { if $H_{1}$ is true }
\end{align*}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-69" class="example"><strong>Example 4.10  (Uniform) </strong></span>Suppose that we have one observation from the uniform distribution on the range <span class="math inline">\((0, \theta)\)</span>. In this case, <span class="math inline">\(f(x)=1 / \theta\)</span> if <span class="math inline">\(0&lt;x&lt;\theta\)</span> and <span class="math inline">\(P(X \leq x)=\frac{x}{\theta}\)</span> for<span class="math inline">\(0&lt;x&lt;\theta\)</span>. We want to test <span class="math inline">\(H_{0}: \theta=1\)</span> against the alternative <span class="math inline">\(H_{1}: \theta=2\)</span>. Suppose we decide arbitrarily that we will reject <span class="math inline">\(H_{0}\)</span> if <span class="math inline">\(X&gt;0.75\)</span>. Then
<span class="math display">\[\begin{align*}
&amp; \alpha=P(\text {Type I error})=P(X&gt;0.75) \text { if } H_{0} \text { is true } \\
&amp; \beta=P(\text {Type II error})=P(X&lt;0.75) \text { if } H_{1} \text { is true }
\end{align*}\]</span>
which will imply:
<span class="math display">\[\begin{array}{r}
\alpha=P(X&gt;0.75 \mid \theta=1)=1-0.75 = 0.25, \\
\beta=P(X&lt;0.75 \mid \theta=2)=0.75 / 2= 0.375.
\end{array}\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-70" class="example"><strong>Example 4.11  (Poisson) </strong></span>The daily demand for a product has a Poisson distribution with mean <span class="math inline">\(\lambda\)</span>, the demands on different days being statistically independent. It is desired to test the hypotheses <span class="math inline">\(H_{0}: \lambda=0.7\)</span> against the alternative <span class="math inline">\(H_{1}: \lambda=0.3\)</span>.
The daily demand will be measured for 20 days, and
the null hypothesis will be rejected if there is no demand on at least 15 of these 20 days.
Calculate the Type I and Type II error probabilities.</p>
<p>Let <span class="math inline">\(p\)</span> denote the probability that the demand on a given day is zero. Then
<span class="math display">\[p=e^{-\lambda}= \begin{cases}e^{-0.7} &amp; \text { under } H_{0} \\ e^{-0.3} &amp; \text { under } H_{1}\end{cases}\]</span></p>
<p>If <span class="math inline">\(X\)</span> denotes the number of days out of 20 with zero demand, it follows that
<span class="math display">\[\begin{align*}
&amp;X \sim \operatorname{Binomial}\left(20, e^{-0.7}\right) \text { under } H_{0}, \\
&amp;X \sim \operatorname{Binomial}\left(20, e^{-0.3}\right) \text { under } H_{1}.
\end{align*}\]</span>
Thus
<span class="math display">\[\begin{align*}
\alpha &amp;=P\left(\text {Reject } H_{0} \mid H_{0} \text { true }\right) \\
&amp;=P\left(X \geq 15 \mid X \sim \operatorname{Binomial}\left(20, e^{-0.7}\right)\right) \\
&amp;=1-P(X \leq 14 \mid X \sim \operatorname{Binomial}(20,0.4966)) \\
&amp;=1-0.98028 \\
&amp;=0.01923 \, (\texttt{1 - pbinom(14, size = 20, prob = 0.4966)})
\end{align*}\]</span></p>
<p>Furthermore
<span class="math display">\[\begin{align*}
\beta &amp;=P\left(\text {Do not reject } H_{0} \mid H_{1} \text { true }\right) \\
&amp;=P\left(X \leq 14 \mid X \sim \operatorname{Binomial}\left(20, e^{-0.3}\right)\right) \\
&amp;=P(X \leq 14 \mid X \sim \operatorname{Binomial}(20,0.7408)) \\
&amp;=0.42023  \, (\texttt{1 - pbinom(14, size = 20, prob = 0.7408)})
\end{align*}\]</span></p>
</div>
<p>Sometimes <span class="math inline">\(\alpha\)</span> is called the size (or significance level) of the test and <span class="math inline">\(\omega \equiv 1-\beta\)</span> is called the power of the test. Ideally, we would like to avoid error so we would like to make both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> as small as possible. In other words, a good test will have small size, but large power. However, it is not possible to make <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> both arbitrarily small. For example if <span class="math inline">\(C=\emptyset\)</span> then <span class="math inline">\(\alpha=0\)</span>, but <span class="math inline">\(\beta=1\)</span>. On the other hand if <span class="math inline">\(C=\mathbf{S}=\mathcal{R}^{n}\)</span> then <span class="math inline">\(\beta=0\)</span>, but <span class="math inline">\(\alpha=1\)</span>.</p>
<p>In this section we have seen how to compute the type I and II error rates given a hypothesis
testing procedure. But how should we construct a hypothesis testing procedure in the first place?
We typically do this by first finding a <em>test statistic</em>: a quantity which
can be computed from the data, whose distribution is known under <span class="math inline">\(H_0\)</span>. We can then check
the actual value of the test statistic is a plausible sample from this null
distribution (the distribution of the test statistic under <span class="math inline">\(H_0\)</span>).
This is all rather abstract. How does it work in a concrete example?</p>
</div>
</div>
<div id="testing-a-normal-mean-t-test" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Testing a normal mean (t-test)<a href="inference.html#testing-a-normal-mean-t-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="introduction-12" class="section level4 hasAnchor" number="4.5.2.1">
<h4><span class="header-section-number">4.5.2.1</span> Introduction<a href="inference.html#introduction-12" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Suppose that we observe data <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> which are modelled as observations of i.i.d. <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> random variables <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>, and we want to test the null hypothesis
<span class="math display">\[H_{0}: \mu=\mu_{0}\]</span>
against the alternative hypothesis
<span class="math display">\[H_{1}: \mu \neq \mu_{0}.\]</span>
We recall that
<span class="math display">\[\sqrt{n} \frac{(\bar{X}-\mu)}{S} \sim t_{n-1}\]</span>
and therefore, when <span class="math inline">\(H_{0}\)</span> is true, often written as under <span class="math inline">\(H_{0}\)</span>,
<span class="math display">\[\sqrt{n} \frac{\left(\bar{X}-\mu_{0}\right)}{S} \sim t_{n-1}.\]</span>
Here <span class="math inline">\(\sqrt{n}\left(\bar{X}-\mu_{0}\right) / s\)</span> is a test statistic:
it can be calculated from the data, and its null distribution is known:
a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<p>This test is called a <span class="math inline">\(t\)</span>-test. We reject the null hypothesis <span class="math inline">\(H_{0}\)</span> in favour of the alternative <span class="math inline">\(H_{1}\)</span> if the observed test statistic seems unlikely to have been generated by the null distribution.</p>
<div class="example">
<p><span id="exm:unlabeled-div-71" class="example"><strong>Example 4.12  (Weight gain) </strong></span>For the weight gain data, if <span class="math inline">\(x\)</span> denotes the differences in weight gain, we have <span class="math inline">\(\bar{x}=0.8672\)</span>, <span class="math inline">\(s=0.9653\)</span> and <span class="math inline">\(n=68\)</span>. Hence our test statistic for the null hypothesis <span class="math inline">\(H_{0}: \mu=\mu_{0}=0\)</span> is
<span class="math display">\[\sqrt{n} \frac{\left(\bar{x}-\mu_{0}\right)}{s}=7.41.\]</span></p>
<p>The observed value of <span class="math inline">\(7.41\)</span> does not seem reasonable from Figure <a href="inference.html#fig:t-pdf-wtgain">4.3</a>, which shows the density of the <span class="math inline">\(t\)</span>-distribution with 67 degrees of freedom, and a vertical line at the observed value of <span class="math inline">\(7.41\)</span>. So there may be evidence here to reject <span class="math inline">\(H_{0}: \mu=0\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:t-pdf-wtgain"></span>
<img src="MATH1063_files/figure-html/t-pdf-wtgain-1.png" alt="The density of the $t_{67}$ distribution. The dashed line shows the observed value of the test statistic for the weight gain data." width="60%" />
<p class="caption">
Figure 4.3: The density of the <span class="math inline">\(t_{67}\)</span> distribution. The dashed line shows the observed value of the test statistic for the weight gain data.
</p>
</div>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-72" class="example"><strong>Example 4.13  (Fast food waiting times) </strong></span>Suppose the manager of the fast food outlet claims that the average waiting time is only 60 seconds. So, we want to test <span class="math inline">\(H_{0}: \mu=60\)</span>. We have <span class="math inline">\(n=20, \bar{x}=67.85, s=18.36\)</span>. Hence our test statistic for the null hypothesis <span class="math inline">\(H_{0}: \mu=\mu_{0}=60\)</span> is
<span class="math display">\[\sqrt{n} \frac{\left(\bar{x}-\mu_{0}\right)}{s}=\sqrt{20} \frac{(67.85-60)}{18.36}=1.91.\]</span></p>
<p>The observed value of <span class="math inline">\(1.91\)</span> may or may not be reasonable from Figure <a href="inference.html#fig:t-pdf-fastfood">4.4</a>, which shows the density of the <span class="math inline">\(t\)</span>-distribution with 19 degrees of freedom, and a vertical line at the observed value of <span class="math inline">\(1.91\)</span>. This value is a bit out in the tail but we are not sure, unlike in the previous weight gain example. So how can we decide whether to reject the null hypothesis?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:t-pdf-fastfood"></span>
<img src="MATH1063_files/figure-html/t-pdf-fastfood-1.png" alt="The density of the $t_{19}$ distribution. The dashed line shows the observed value of the test statistic for the fast food data." width="60%" />
<p class="caption">
Figure 4.4: The density of the <span class="math inline">\(t_{19}\)</span> distribution. The dashed line shows the observed value of the test statistic for the fast food data.
</p>
</div>
</div>
</div>
<div id="the-significance-level" class="section level4 hasAnchor" number="4.5.2.2">
<h4><span class="header-section-number">4.5.2.2</span> The significance level<a href="inference.html#the-significance-level" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In the weight gain example, it seems that there is enough evidence to reject <span class="math inline">\(H_{0}\)</span>, but how extreme (far from the mean of the null distribution) should the test statistic be in order for <span class="math inline">\(H_{0}\)</span> to be rejected? The significance level of the test, <span class="math inline">\(\alpha\)</span>, is the probability that we will erroneously reject <span class="math inline">\(H_{0}\)</span> (called Type I error as discussed before). Clearly we would like <span class="math inline">\(\alpha\)</span> to be small, but making it too small risks failing to reject <span class="math inline">\(H_{0}\)</span> even when it provides a poor model for the observed data (Type II error). Conventionally, <span class="math inline">\(\alpha\)</span> is usually set to a value of <span class="math inline">\(0.05\)</span>, or <span class="math inline">\(5 \%\)</span>. Therefore we reject <span class="math inline">\(H_{0}\)</span> when the test statistic lies in a rejection region which has probability <span class="math inline">\(\alpha=0.05\)</span> under the null distribution.</p>
</div>
<div id="rejection-region" class="section level4 hasAnchor" number="4.5.2.3">
<h4><span class="header-section-number">4.5.2.3</span> Rejection region<a href="inference.html#rejection-region" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For the t-test, the null distribution is <span class="math inline">\(t_{n-1}\)</span> where <span class="math inline">\(n\)</span> is the sample size, so the rejection region for the test corresponds to a region of total probability <span class="math inline">\(\alpha=0.05\)</span> comprising the ‘most extreme’ values in the direction of the alternative hypothesis. If the alternative hypothesis is two-sided, e.g. <span class="math inline">\(H_{1}: \mu \neq \mu_{0}\)</span>, then this is obtained as below, where the two shaded regions both have area (probability) <span class="math inline">\(\alpha / 2=0.025\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:t-rejection"></span>
<img src="MATH1063_files/figure-html/t-rejection-1.png" alt="The shaded area shows the rejection region for a t-test. $h$ is chosen to make the shaded area equal to the significance level $1-\alpha$" width="60%" />
<p class="caption">
Figure 4.5: The shaded area shows the rejection region for a t-test. <span class="math inline">\(h\)</span> is chosen to make the shaded area equal to the significance level <span class="math inline">\(1-\alpha\)</span>
</p>
</div>
<p>The value of <span class="math inline">\(h\)</span> depends on the sample size <span class="math inline">\(n\)</span> and can be found in R with the <code>qt</code> command.
Note that we need to put <span class="math inline">\(n-1\)</span> in the <code>df</code> argument of <code>qt</code>.
So for <span class="math inline">\(n = 100\)</span>, we can find <span class="math inline">\(h\)</span> with</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="inference.html#cb48-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> <span class="dv">99</span>)</span></code></pre></div>
<pre><code>## [1] 1.984217</code></pre>
For some other values of <span class="math inline">\(n\)</span>, we have
<p>where the last value for <span class="math inline">\(n=\infty\)</span> is obtained from the normal distribution.</p>
<p>However, if the alternative hypothesis is one-sided, e.g. <span class="math inline">\(H_{1}: \mu&gt;\mu_{0}\)</span>, then the critical region will only be in the right tail:
reject if the test statistic is greater than some value <span class="math inline">\(h\)</span>.
In this case, we choose <span class="math inline">\(h\)</span> such that the area to the right of <span class="math inline">\(h\)</span>
(under the <span class="math inline">\(t_{n-1}\)</span> pdf)
is <span class="math inline">\(\alpha\)</span>.
So for <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(\alpha = 0.05\)</span>, we can find this <span class="math inline">\(h\)</span> with</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="inference.html#cb50-1" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.95</span>, <span class="at">df =</span> <span class="dv">99</span>)</span></code></pre></div>
<pre><code>## [1] 1.660391</code></pre>
For some other values of <span class="math inline">\(n\)</span>, we have
</div>
<div id="summary-of-the-t-test-procedure" class="section level4 hasAnchor" number="4.5.2.4">
<h4><span class="header-section-number">4.5.2.4</span> Summary of the t-test procedure<a href="inference.html#summary-of-the-t-test-procedure" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Suppose that we observe data <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> which are modelled as observations of i.i.d. <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> random variables <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> and we want to test the null hypothesis <span class="math inline">\(H_{0}: \mu=\mu_{0}\)</span> against the alternative hypothesis <span class="math inline">\(H_{1}: \mu \neq \mu_{0}\)</span> :</p>
<ol style="list-style-type: decimal">
<li><p>Compute the test statistic
<span class="math display">\[t=\sqrt{n} \frac{\left(\bar{x}-\mu_{0}\right)}{s}.\]</span></p></li>
<li><p>For chosen significance level <span class="math inline">\(\alpha\)</span> (usually 0.05) calculate the rejection region for <span class="math inline">\(t\)</span>, which is of the form <span class="math inline">\(|t|&gt;h\)</span> where <span class="math inline">\(-h\)</span> is the <span class="math inline">\(\alpha / 2\)</span> percentile of the null distribution, <span class="math inline">\(t_{n-1}\)</span>.</p></li>
<li><p>If your computed <span class="math inline">\(t\)</span> lies in the rejection region, i.e. <span class="math inline">\(|t|&gt;h\)</span>, you report that <span class="math inline">\(H_{0}\)</span> is rejected in favour of <span class="math inline">\(H_{1}\)</span> at the chosen level of significance. If <span class="math inline">\(t\)</span> does not lie in the rejection region, you report that <span class="math inline">\(H_{0}\)</span> is not rejected. (Never refer to ‘accepting’ a hypothesis.)</p></li>
</ol>
</div>
<div id="examples" class="section level4 hasAnchor" number="4.5.2.5">
<h4><span class="header-section-number">4.5.2.5</span> Examples<a href="inference.html#examples" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="example">
<p><span id="exm:unlabeled-div-73" class="example"><strong>Example 4.14  (Fast food waiting times) </strong></span>We would like to test <span class="math inline">\(H_{0}: \mu=60\)</span> against the alternative <span class="math inline">\(H_{1}: \mu&gt;60\)</span>, as this alternative will refute the claim of the store manager that customers only wait for a maximum of one minute. We calculated the observed value to be <span class="math inline">\(1.91\)</span>. This is a one-sided test and for a <span class="math inline">\(5 \%\)</span> level of significance, the critical value <span class="math inline">\(h\)</span> will come from <span class="math inline">\(\texttt{qt(0.95, df = 19)}=1.73\)</span>. Thus the observed value is higher than the critical value so we will reject the null hypothesis, disputing the manager’s claim regarding a minute wait.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-74" class="example"><strong>Example 4.15  (Weight gain) </strong></span>For the weight gain example <span class="math inline">\(\bar{x}=0.8671, s=0.9653, n=68\)</span>. Then, we would be interested in testing <span class="math inline">\(H_{0}: \mu=0\)</span> against the alternative hypothesis <span class="math inline">\(H_{1}: \mu \neq 0\)</span> in the model that the data are observations of i.i.d. <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> random variables.</p>
<ul>
<li>We obtain the test statistic
<span class="math display">\[t=\sqrt{n} \frac{\left(\bar{x}-\mu_{0}\right)}{s}=\sqrt{68} \frac{(0.8671-0)}{0.9653}=7.41.\]</span></li>
<li>Under <span class="math inline">\(H_{0}\)</span> this is an observation from a <span class="math inline">\(t_{67}\)</span> distribution. For significance level <span class="math inline">\(\alpha=0.05\)</span> the rejection region is <span class="math inline">\(|t|&gt;1.996\)</span>.</li>
<li>Our computed test statistic lies in the rejection region, i.e. <span class="math inline">\(|t|&gt;1.996\)</span>, so <span class="math inline">\(H_{0}\)</span> is rejected in favour of <span class="math inline">\(H_{1}\)</span> at the <span class="math inline">\(5 \%\)</span> level of significance.</li>
</ul>
<p>In R we can perform the test as follows:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="inference.html#cb52-1" tabindex="-1"></a>wtgain<span class="sc">$</span>diff <span class="ot">&lt;-</span> wtgain<span class="sc">$</span>final <span class="sc">-</span> wtgain<span class="sc">$</span>initial</span>
<span id="cb52-2"><a href="inference.html#cb52-2" tabindex="-1"></a><span class="fu">t.test</span>(wtgain<span class="sc">$</span>diff)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  wtgain$diff
## t = 7.4074, df = 67, p-value = 2.813e-10
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.6334959 1.1008265
## sample estimates:
## mean of x 
## 0.8671612</code></pre>
<p>This gives the results <span class="math inline">\(\mathrm{t}=7.4074\)</span>, and <span class="math inline">\(\mathrm{df}=67\)</span>.</p>
</div>
</div>
<div id="p-values" class="section level4 hasAnchor" number="4.5.2.6">
<h4><span class="header-section-number">4.5.2.6</span> p-values<a href="inference.html#p-values" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The result of a test is most commonly summarised by rejection or non-rejection of <span class="math inline">\(H_{0}\)</span> at the stated level of significance. An alternative, which you may see in practice, is the computation of a p-value. This is the probability that the null distribution would have generated the actual observed value of the statistic or something more extreme. A small p-value is evidence against the null hypothesis, as it indicates that the observed data were unlikely to have been generated by the null distribution. In many examples a threshold of <span class="math inline">\(0.05\)</span> is used, below which the null hypothesis is rejected as being insufficiently well-supported by the observed data.</p>
<p>For the t-test with a two-sided alternative, the p-value is given by:<span class="math display">\[p=P\left(|T|&gt;\left|t_{\text{obs}}\right|\right)=2 P\left(T&gt;\left|t_{\text{obs}}\right|\right),\]</span>
where <span class="math inline">\(T\)</span> has a <span class="math inline">\(t_{n-1}\)</span> distribution and <span class="math inline">\(t_{\text{obs }}\)</span> is the observed sample value.</p>
<p>However, if the alternative is one-sided and to the right then the p-value is given by:
<span class="math display">\[p=P\left(T&gt;t_{\text{obs}}\right),\]</span>
where <span class="math inline">\(T\)</span> has a <span class="math inline">\(t_{n-1}\)</span> distribution and <span class="math inline">\(t_{\text{obs}}\)</span> is the observed sample value.</p>
<p>A small p-value corresponds to an observation of <span class="math inline">\(T\)</span> that is improbable (since it is far out in the low probability tail area) under <span class="math inline">\(H_{0}\)</span> and hence provides evidence against <span class="math inline">\(H_{0}\)</span>. The p-value should not be misinterpreted as the probability that <span class="math inline">\(H_{0}\)</span> is true. <span class="math inline">\(H_{0}\)</span> is not a random event (under our models) and so cannot be assigned a probability. The null hypothesis is rejected at significance level <span class="math inline">\(\alpha\)</span> if the p-value for the test is less than <span class="math inline">\(\alpha\)</span>.
<span class="math display">\[\text { Reject } H_{0} \text { if p-value }&lt;\alpha.\]</span></p>
<!-- TODO: check for consistent naming of fast food / weight gain examples -->
<div class="example">
<p><span id="exm:unlabeled-div-75" class="example"><strong>Example 4.16  (Fast food waiting times) </strong></span>In the fast food example, a test of <span class="math inline">\(H_{0}: \mu=60\)</span> resulted in a test statistic <span class="math inline">\(t=1.91\)</span>. Then the p-value is given by
<span class="math display">\[p=P(T&gt;1.91)=0.036 \text {, when } T \sim t_{19}.\]</span></p>
<p>This is the area of the shaded region in Figure <a href="inference.html#fig:p-value-fastfood">4.6</a>.
In R it is</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="inference.html#cb54-1" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fl">1.91</span>, <span class="at">df =</span> <span class="dv">19</span>) </span></code></pre></div>
<pre><code>## [1] 0.03567359</code></pre>
<p>The p-value <span class="math inline">\(0.036\)</span> indicates some evidence against the manager’s claim at the <span class="math inline">\(5 \%\)</span> level of significance but not the <span class="math inline">\(1 \%\)</span> level of significance.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:p-value-fastfood"></span>
<img src="MATH1063_files/figure-html/p-value-fastfood-1.png" alt="The area of the shaded region (under the $t_{19}$ pdf) is the p-value for the one-sided hypothesis test in the fast food example" width="60%" />
<p class="caption">
Figure 4.6: The area of the shaded region (under the <span class="math inline">\(t_{19}\)</span> pdf) is the p-value for the one-sided hypothesis test in the fast food example
</p>
</div>
</div>
<p>When the alternative hypothesis is two-sided the p-value has to be calculated from <span class="math inline">\(P\left(|T|&gt;t_{\text {obs }}\right)\)</span>, where <span class="math inline">\(t_{\text {obs }}\)</span> is the observed value and <span class="math inline">\(T\)</span> follows the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> df.</p>
<div class="example">
<p><span id="exm:unlabeled-div-76" class="example"><strong>Example 4.17  (Weight gain) </strong></span>Because the alternative is two-sided, the p-value is given by:
<span class="math display">\[p=P(|T|&gt;7.41)=2.78 \times 10^{-10} \approx 0.0, \text { when } T \sim t_{67}.\]</span>
This very small p-value indicates very strong evidence against the null hypothesis of no weight gain in the first year of college.</p>
</div>
</div>
<div id="equivalence-of-testing-and-interval-estimation" class="section level4 hasAnchor" number="4.5.2.7">
<h4><span class="header-section-number">4.5.2.7</span> Equivalence of testing and interval estimation<a href="inference.html#equivalence-of-testing-and-interval-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Note that the <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> in the weight gain example has previously been calculated to be <span class="math inline">\((0.6335,1.1008)\)</span> in
Example <a href="inference.html#exm:wtgain-ci">4.9</a>.
This interval does not include the hypothesised value 0 of <span class="math inline">\(\mu\)</span>. Hence we can conclude that the hypothesis test at the <span class="math inline">\(5 \%\)</span> level of significance will reject the null hypothesis <span class="math inline">\(H_{0}: \mu=0\)</span>.</p>
<p>This is because <span class="math display">\[\left|T_\text{obs}=\frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{s}\right|&gt;h\]</span> implies and is implied by <span class="math inline">\(\mu_{0}\)</span> being outside the interval <span class="math display">\[(\bar{x}-h s / \sqrt{n}, \bar{x}+h s / \sqrt{n}).\]</span> Notice that <span class="math inline">\(h\)</span> is the same in both. For this reason we often just calculate the confidence interval and take the reject/do not reject decision merely by inspection.</p>
</div>
</div>
<div id="two-sample-t-tests" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Two sample t-tests<a href="inference.html#two-sample-t-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that we observe two samples of data, <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> and <span class="math inline">\(y_{1}, \ldots, y_{m}\)</span>, and that we propose to model them as observations of
<span class="math display">\[X_{1}, \ldots, X_{n} \stackrel{\text{ i.i.d. }}{\sim} N\left(\mu_{X}, \sigma_{X}^{2}\right)\]</span>
and
<span class="math display">\[Y_{1}, \ldots, Y_{m} \stackrel{\text { i.i.d. }}{\sim} N\left(\mu_{Y}, \sigma_{Y}^{2}\right)\]</span>
respectively, where it is also assumed that the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables are independent of each other. Suppose that we want to test the hypothesis that the distributions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are identical, that is
<span class="math display">\[H_{0}: \mu_{X}=\mu_{Y}, \quad \sigma_{X}=\sigma_{Y}=\sigma\]</span>
against the alternative hypothesis
<span class="math display">\[H_{1}: \mu_{X} \neq \mu_{Y}.\]</span></p>
<!-- TODO: change to remove $\sigma_X$, $\sigma_Y$ from setup? -->
<!-- TODO more specific ref? -->
<p>In the Chapter 3 we proved that
<span class="math display">\[\bar{X} \sim N\left(\mu_{X}, \sigma_{X}^{2} / n\right) \text { and } \bar{Y} \sim N\left(\mu_{Y}, \sigma_{Y}^{2} / m\right)\]</span>
and therefore
<span class="math display">\[\bar{X}-\bar{Y} \sim N\left(\mu_{X}-\mu_{Y}, \frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}\right).\]</span></p>
<p>Hence, under <span class="math inline">\(H_{0}\)</span>,
<span class="math display">\[\bar{X}-\bar{Y} \sim N\left(0, \sigma^{2}\left[\frac{1}{n}+\frac{1}{m}\right]\right) \Rightarrow \sqrt{\frac{n m}{n+m}} \frac{(\bar{X}-\bar{Y})}{\sigma} \sim N(0,1).\]</span></p>
<p>The involvement of the (unknown) <span class="math inline">\(\sigma\)</span> above means that this is not a pivotal test statistic. It will be proved in MATH2011 that if <span class="math inline">\(\sigma^2\)</span> is replaced by its unbiased estimator <span class="math inline">\(S^2\)</span>, which here is the two-sample estimator of the common variance, given by
<span class="math display">\[S^{2}=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}+\sum_{i=1}^{m}\left(Y_{i}-\bar{Y}\right)^{2}}{n+m-2},\]</span>
then
<span class="math display">\[\sqrt{\frac{n m}{n+m}} \frac{(\bar{X}-\bar{Y})}{S} \sim t_{n+m-2}.\]</span>
Hence
<span class="math display">\[t=\sqrt{\frac{n m}{n+m}} \frac{(\bar{x}-\bar{y})}{s}\]</span>
is a test statistic for this test. The rejection region is <span class="math inline">\(|t|&gt;h\)</span> where <span class="math inline">\(-h\)</span> is the <span class="math inline">\(\alpha / 2\)</span> (usually <span class="math inline">\(0.025\)</span> ) percentile of <span class="math inline">\(t_{n+m-2}\)</span>.</p>
<p>From the hypothesis testing, a <span class="math inline">\(100(1-\alpha) \%\)</span> confidence interval
for <span class="math inline">\(\mu_{X}-\mu_{Y}\)</span>
is given by
<span class="math display">\[\bar{x}-\bar{y} \pm h \sqrt{\frac{n+m}{n m}} s,\]</span>
where <span class="math inline">\(-h\)</span> is the <span class="math inline">\(\alpha / 2\)</span> (usually <span class="math inline">\(0.025\)</span> ) percentile of <span class="math inline">\(t_{n+m-2}\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-77" class="example"><strong>Example 4.18  (Fast food waiting times) </strong></span>In this example, we would like to know if there are significant differences between the AM and PM waiting times. Here <span class="math inline">\(n=m=10\)</span>, <span class="math inline">\(\bar{x}=68.9\)</span>, <span class="math inline">\(\bar{y}=66.8\)</span>, <span class="math inline">\(s_{x}^{2}=538.22\)</span> and <span class="math inline">\(s_{y}^{2}=171.29\)</span>. From this we calculate,
<span class="math display">\[s^{2}=\frac{(n-1) s_{x}^{2}+(m-1) s_{y}^{2}}{n+m-2}=354.8,\]</span>
and
<span class="math display">\[t_{\text{obs}}=\sqrt{\frac{n m}{n+m}} \frac{(\bar{x}-\bar{y})}{s}=0.25.\]</span>
This is not significant as the critical value <span class="math inline">\(h = \texttt{qt(0.975, df = 18)}=2.10\)</span> is larger in absolute value than <span class="math inline">\(0.25\)</span>.
We can conduct the test easily in R:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="inference.html#cb56-1" tabindex="-1"></a>fastfood_am <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">38</span>, <span class="dv">100</span>, <span class="dv">64</span>, <span class="dv">43</span>, <span class="dv">63</span>, <span class="dv">59</span>, <span class="dv">107</span>, <span class="dv">52</span>, <span class="dv">86</span>, <span class="dv">77</span>)</span>
<span id="cb56-2"><a href="inference.html#cb56-2" tabindex="-1"></a>fastfood_pm <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">45</span>, <span class="dv">62</span>, <span class="dv">52</span>, <span class="dv">72</span>, <span class="dv">81</span>, <span class="dv">88</span>, <span class="dv">64</span>, <span class="dv">75</span>, <span class="dv">59</span>, <span class="dv">70</span>)</span>
<span id="cb56-3"><a href="inference.html#cb56-3" tabindex="-1"></a><span class="fu">t.test</span>(fastfood_am, fastfood_pm)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  fastfood_am and fastfood_pm
## t = 0.24929, df = 14.201, p-value = 0.8067
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.9434  20.1434
## sample estimates:
## mean of x mean of y 
##      68.9      66.8</code></pre>
<p>It automatically calculates the test statistic as <span class="math inline">\(0.249\)</span> and a p-value of <span class="math inline">\(0.8067\)</span>. It also obtains the <span class="math inline">\(95 \%\)</span> CI given by <span class="math inline">\((-15.94,20.14)\)</span>.</p>
</div>
</div>
<div id="paired-t-test" class="section level3 hasAnchor" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> Paired t-test<a href="inference.html#paired-t-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes the assumption that the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> variables are independent of each other is unlikely to be valid, due to the design of the study. The most common example of this is where <span class="math inline">\(n=m\)</span> and data are paired. For example, a measurement has been made on patients before treatment <span class="math inline">\((X)\)</span> and then again on the same set of patients after treatment <span class="math inline">\((Y)\)</span>. Recall the weight gain example is exactly of this type. In such examples, we proceed by computing data on the differences
<span class="math display">\[z_{i}=x_{i}-y_{i}, \quad i=1, \ldots, n\]</span>
and modelling these differences as observations of i.i.d. <span class="math inline">\(N\left(\mu_{z}, \sigma_{Z}^{2}\right)\)</span> variables <span class="math inline">\(Z_{1}, \ldots, Z_{n}\)</span>. Then, a test of the hypothesis <span class="math inline">\(\mu_{X}=\mu_{Y}\)</span> is achieved by testing <span class="math inline">\(\mu_{Z}=0\)</span>, which is just a standard (one sample) t-test, as described previously.</p>
<div class="example">
<p><span id="exm:unlabeled-div-78" class="example"><strong>Example 4.19  </strong></span>Water-quality researchers wish to measure the biomass to chlorophyll ratio for phytoplankton (in milligrams per litre of water). There are two possible tests, one less expensive than the other. To see whether the two tests give the same results, ten water samples were taken and each was measured both ways. The results are as follows:</p>
</div>
<p>To test the null-hypothesis
<span class="math display">\[H_{0}: \mu_{Z}=0 \text { against } H_{1}: \mu_{Z} \neq 0\]</span>
we use the test statistic <span class="math inline">\(t=\sqrt{n} \frac{\bar{z}}{s_{z}}\)</span>, where <span class="math inline">\(s_{z}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(z_{i}-\bar{z}\right)^{2}\)</span>.</p>
<p>From the hypothesis testing, a <span class="math inline">\(100(1-\alpha) \%\)</span> confidence interval
for <span class="math inline">\(\mu_Z\)</span> is given by <span class="math inline">\(\bar{z} \pm h \frac{s_{z}}{\sqrt{n}}\)</span>, where <span class="math inline">\(h\)</span> is the critical value of the <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. In R we perform the test as follows:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="inference.html#cb58-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">45.9</span>, <span class="fl">57.6</span>, <span class="fl">54.9</span>, <span class="fl">38.7</span>, <span class="fl">35.7</span>, <span class="fl">39.2</span>, <span class="fl">45.9</span>, <span class="fl">43.2</span>, <span class="fl">45.4</span>, <span class="fl">54.8</span>)</span>
<span id="cb58-2"><a href="inference.html#cb58-2" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">48.2</span>, <span class="fl">64.2</span>, <span class="fl">56.8</span>, <span class="fl">47.2</span>, <span class="fl">43.7</span>, <span class="fl">45.7</span>, <span class="fl">53.0</span>, <span class="fl">52.0</span>, <span class="fl">45.1</span>, <span class="fl">57.5</span>)</span>
<span id="cb58-3"><a href="inference.html#cb58-3" tabindex="-1"></a></span>
<span id="cb58-4"><a href="inference.html#cb58-4" tabindex="-1"></a><span class="fu">t.test</span>(x, y, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  x and y
## t = -5.0778, df = 9, p-value = 0.0006649
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -7.531073 -2.888927
## sample estimates:
## mean difference 
##           -5.21</code></pre>
<p>This gives the test statistic <span class="math inline">\(t_{\text{obs}}=-5.0778\)</span> with a df of 9 and a p-value <span class="math inline">\(=0.0006649\)</span>. Thus we reject the null hypothesis. The associated <span class="math inline">\(95 \%\)</span> CI is <span class="math inline">\((-7.53,-2.89)\)</span>.</p>
<p>The values of the second test are significantly higher than the ones of the first test, and so the second test cannot be considered as a replacement for the first.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH1063.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
